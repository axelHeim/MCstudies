{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time at start = 2021-09-20 22:15:04.273306\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "print(\"time at start =\", now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTCondorRun: -f\n"
     ]
    }
   ],
   "source": [
    "HTCondorRun = str(sys.argv[1])\n",
    "print(\"HTCondorRun:\",HTCondorRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = True\n",
    "tmp_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs_path = \"/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/\"\n",
    "\n",
    "data_subdir = \"Dstlnu_Hc_corr_BsigX_separation_dataRun1/\"   \n",
    "root_subdir = \"axheim_data2_MC14_100kEvts/\"   \n",
    "\n",
    "root_path = nfs_path + \"createBranchSeparatorData/\" + root_subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = \"merged_\"\n",
    "if tmp_data:\n",
    "    merged += \"tmp_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileY4S = uproot.open(root_path + merged + \"DXtagDstl.root:variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/createBranchSeparatorData/axheim_data2_MC14_100kEvts/merged_gammas.root:variables\n",
      "/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/createBranchSeparatorData/axheim_data2_MC14_100kEvts/merged_electrons.root:variables\n",
      "/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/createBranchSeparatorData/axheim_data2_MC14_100kEvts/merged_pions.root:variables\n",
      "/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/createBranchSeparatorData/axheim_data2_MC14_100kEvts/merged_kaons.root:variables\n",
      "/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/createBranchSeparatorData/axheim_data2_MC14_100kEvts/merged_muons.root:variables\n"
     ]
    }
   ],
   "source": [
    "names = [\"gammas\",\"electrons\",\"pions\",\"kaons\",\"muons\"]\n",
    "dfs = []\n",
    "for name in names:\n",
    "    filename = root_path + merged + \"{}.root:variables\".format(name)\n",
    "    print(filename)\n",
    "    tmpFileFSPs = uproot.open(filename)\n",
    "    df_tmp = tmpFileFSPs.arrays(library=\"pd\")\n",
    "    dfs.append(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FSPs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y4S = fileY4S.arrays(library=\"pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9865292\n",
      "211319\n"
     ]
    }
   ],
   "source": [
    "print(df_FSPs.shape[0])\n",
    "print(df_Y4S.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete FSPs for which no Y4S file entry was found\n",
    "df_FSPs = df_FSPs[df_FSPs['__event__'].isin(df_Y4S[\"__event__\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9754944\n",
      "211319\n"
     ]
    }
   ],
   "source": [
    "print(df_FSPs.shape[0])\n",
    "print(df_Y4S.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take a sample if used in notebook for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Y4Ssample = df_Y4S.sample(n=100)\n",
    "#df_FSPssample = df_FSPs[df_FSPs['__event__'].isin(df_Y4Ssample[\"__event__\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Y4S=df_Y4Ssample\n",
    "#df_FSPs=df_FSPssample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_FSPs.shape[0]: 4665\n",
      "df_Y4S.shape[0]: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"df_FSPs.shape[0]:\",df_FSPs.shape[0])\n",
    "print(\"df_Y4S.shape[0]:\",df_Y4S.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete particles which occur more than ones based on uniqueParticleIdentifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupsFSPs_uniqParID = pd.DataFrame({'count' : df_FSPs.groupby( [\"__event__\",\"uniqueParticleIdentifier\"] ).size()}).reset_index()\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#    print(groupsFSPs_uniqParID.sort_values(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_FSPs.shape[0]: 4665\n",
      "groupsFSPs_uniqParID.shape[0]: 3476\n",
      "df_Y4S.shape[0]: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"df_FSPs.shape[0]:\",df_FSPs.shape[0])\n",
    "print(\"groupsFSPs_uniqParID.shape[0]:\",groupsFSPs_uniqParID.shape[0])\n",
    "print(\"df_Y4S.shape[0]:\",df_Y4S.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_FSPs[basf2_used].value_counts(): 0.0    2456\n",
      "1.0    2209\n",
      "Name: basf2_used, dtype: int64\n",
      "df_FSPs[basf2_used].value_counts(): 1.0    2209\n",
      "0.0    1267\n",
      "Name: basf2_used, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# delete particles which occur more than ones (keep first) and if possible keep the one with basf2_used==1\n",
    "print(\"df_FSPs[basf2_used].value_counts():\",df_FSPs[\"basf2_used\"].value_counts())\n",
    "df_FSPs = df_FSPs.sort_values(\"basf2_used\",ascending=False).drop_duplicates(subset=(\"__event__\",\"uniqueParticleIdentifier\"), keep='first')\n",
    "print(\"df_FSPs[basf2_used].value_counts():\",df_FSPs[\"basf2_used\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_FSPs.shape[0]: 3476\n"
     ]
    }
   ],
   "source": [
    "print(\"df_FSPs.shape[0]:\",df_FSPs.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check if category combinations make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basf2_used</th>\n",
       "      <th>basf2_Bsig</th>\n",
       "      <th>basf2_X</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   basf2_used  basf2_Bsig  basf2_X  count\n",
       "0         0.0         0.0      0.0   1267\n",
       "1         1.0         0.0      0.0    391\n",
       "2         1.0         0.0      1.0   1114\n",
       "3         1.0         1.0      0.0    704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupsAllFSPs = pd.DataFrame({'count' : df_FSPs.groupby( [\"basf2_used\",\"basf2_Bsig\",\"basf2_X\"] ).size()}).reset_index()\n",
    "groupsAllFSPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add two cols with extra info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create col with the particles mother B's uniqueParticleIdentifier\n",
    "def B_ID(s):\n",
    "    label = 0\n",
    "    for i in range(10): \n",
    "        mcMotheri_uniqParID = \"mcMother{}_uniqParID\".format(i)\n",
    "        if ((s[mcMotheri_uniqParID]) == 83886082.0):\n",
    "            label = 83886082   \n",
    "        elif ((s[mcMotheri_uniqParID]) == 83886081.0):\n",
    "            label = 83886081   \n",
    "    return label\n",
    "df_FSPs['B_ID'] = df_FSPs.apply(B_ID, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if particle was used by basf2 but neither for B-sig or X it is from the Hc\n",
    "def Hc(s):\n",
    "    label = 0\n",
    "    if ((s[\"basf2_used\"] == 1.0) & (s[\"basf2_Bsig\"] == 0.0) & (s[\"basf2_X\"] == 0.0)):\n",
    "            label = 1   \n",
    "    \n",
    "    return label\n",
    "df_FSPs['Hc'] = df_FSPs.apply(Hc, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this shows that Hc is sometimes combined from both B's which is of course wrong\n",
    "#groupsAllFSPs = pd.DataFrame({'count' : df_FSPs.groupby( [\"__event__\",\"B_ID\",\"Hc\",\"basf2_used\",\"basf2_Bsig\",\"basf2_X\"] ).size()}).reset_index()\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#    print(groupsAllFSPs.sort_values(\"Hc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create df with per event info about which B is sig and which is tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupsAllFSPs = pd.DataFrame({'count' : df_FSPs.groupby([\"__event__\",\"B_ID\",\"Hc\"]).size(),\n",
    "                             'sum_p': df_FSPs.groupby([\"__event__\",\"B_ID\",\"Hc\"])[\"p\"].sum()}).reset_index()\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#    print(groupsAllFSPs[(groupsAllFSPs[\"__event__\"] == 3183239)].sort_values(\"__event__\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(groupsAllFSPs[groupsAllFSPs[\"Hc\"] == 1].sort_values(\"__event__\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "events=[]\n",
    "B_tag_IDs=[]\n",
    "B_sig_IDs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0 cases, Btag (B mother of Hc) was unclear\n",
      "equals to 0.0 %\n"
     ]
    }
   ],
   "source": [
    "unclearHc = 0\n",
    "for evt in pd.unique(groupsAllFSPs[groupsAllFSPs[\"Hc\"] == 1][\"__event__\"]):\n",
    "    # sort by sum_p to take \"max_count_idx\" from the H_c particles with more momentum if two categories have the same particle count\n",
    "    singleEvt_Hcs = groupsAllFSPs[(groupsAllFSPs[\"Hc\"] == 1) & (groupsAllFSPs[\"__event__\"] == evt)].sort_values(\"sum_p\",ascending=False)\n",
    "    \n",
    "    # B_ID=0 => background, so take the other one if available\n",
    "    singleEvt_Hcs = singleEvt_Hcs[(singleEvt_Hcs[\"B_ID\"] != 0)]\n",
    "    \n",
    "    if singleEvt_Hcs.empty:\n",
    "        unclearHc += 1\n",
    "        continue\n",
    "    \n",
    "    max_count_idx = singleEvt_Hcs[\"count\"].idxmax()\n",
    "    \n",
    "    #print((max_count_idx))\n",
    "    max_count_row = singleEvt_Hcs.loc[[max_count_idx]]\n",
    "       \n",
    "    \n",
    "    #print(max_count_row,'\\n\\n\\n\\n')\n",
    "\n",
    "        \n",
    "    events.append(max_count_row.iloc[0]['__event__'])\n",
    "    B_tag_IDs.append(max_count_row.iloc[0]['B_ID']) # this is Btag because it is Hc's mother B\n",
    "    Bsig_tmp = 0\n",
    "    if B_tag_IDs[-1] == 83886082:\n",
    "        Bsig_tmp = 83886081.0\n",
    "    elif B_tag_IDs[-1] == 83886081:\n",
    "        Bsig_tmp = 83886082.0\n",
    "    #else:\n",
    "    #    unclearHc +=1\n",
    "    #    print(singleEvt_Hcs)\n",
    "    #    print(events[-1],B_tag_IDs[-1],max_count_idx)\n",
    "    #    raise ValueError('Btag/Bsig assignment unclear')\n",
    "    B_sig_IDs.append(Bsig_tmp)\n",
    "    \n",
    "print(\"in\",unclearHc,\"cases, Btag (B mother of Hc) was unclear\")\n",
    "print(\"equals to\",round(unclearHc/(len(B_sig_IDs)+unclearHc) , 4)*100,\"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_Bs = pd.DataFrame(\n",
    "{\"__event__\" : events,\n",
    "\"B_tag_ID\" : B_tag_IDs,\n",
    "\"B_sig_ID\" : B_sig_IDs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_FSPs.shape[0]: 3476\n",
      "df_FSPs.shape[0]: 3476\n"
     ]
    }
   ],
   "source": [
    "# throw away events with unclear Btag\n",
    "print(\"df_FSPs.shape[0]:\",df_FSPs.shape[0])\n",
    "df_FSPs = df_FSPs[df_FSPs['__event__'].isin(event_Bs[\"__event__\"])]\n",
    "print(\"df_FSPs.shape[0]:\",df_FSPs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__event__</th>\n",
       "      <th>B_tag_ID</th>\n",
       "      <th>B_sig_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190398.0</td>\n",
       "      <td>83886082.0</td>\n",
       "      <td>83886081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1281176.0</td>\n",
       "      <td>83886082.0</td>\n",
       "      <td>83886081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2126042.0</td>\n",
       "      <td>83886082.0</td>\n",
       "      <td>83886081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2653187.0</td>\n",
       "      <td>83886082.0</td>\n",
       "      <td>83886081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2686695.0</td>\n",
       "      <td>83886082.0</td>\n",
       "      <td>83886081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3765558.0</td>\n",
       "      <td>83886082.0</td>\n",
       "      <td>83886081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3988810.0</td>\n",
       "      <td>83886082.0</td>\n",
       "      <td>83886081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4222628.0</td>\n",
       "      <td>83886081.0</td>\n",
       "      <td>83886082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5241158.0</td>\n",
       "      <td>83886081.0</td>\n",
       "      <td>83886082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5837467.0</td>\n",
       "      <td>83886082.0</td>\n",
       "      <td>83886081.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   __event__    B_tag_ID    B_sig_ID\n",
       "0   190398.0  83886082.0  83886081.0\n",
       "1  1281176.0  83886082.0  83886081.0\n",
       "2  2126042.0  83886082.0  83886081.0\n",
       "3  2653187.0  83886082.0  83886081.0\n",
       "4  2686695.0  83886082.0  83886081.0\n",
       "5  3765558.0  83886082.0  83886081.0\n",
       "6  3988810.0  83886082.0  83886081.0\n",
       "7  4222628.0  83886081.0  83886082.0\n",
       "8  5241158.0  83886081.0  83886082.0\n",
       "9  5837467.0  83886082.0  83886081.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_Bs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_tag_ID</th>\n",
       "      <th>B_sig_ID</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83886081.0</td>\n",
       "      <td>83886082.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83886082.0</td>\n",
       "      <td>83886081.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     B_tag_ID    B_sig_ID  count\n",
       "0  83886081.0  83886082.0     55\n",
       "1  83886082.0  83886081.0     45"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that B-tag and B-sig are not equal for any event -> only 2 rows shall appear here\n",
    "pd.DataFrame({'count' : event_Bs.groupby([\"B_tag_ID\",\"B_sig_ID\"]).size()}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save dataframes on NFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HTCondorRun == \"isHTCondorRun\":\n",
    "    df_FSPs.to_csv(root_path + \"df_FSPs_preProcessed.csv\")\n",
    "    event_Bs.to_csv(root_path + \"event_Bs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_FSPs = pd.read_csv(root_path + \"df_FSPs_preProcessed.csv\")\n",
    "#event_Bs = pd.read_csv(root_path + \"event_Bs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete Hc particles, after loading data, so saved df's cotain the Hc particles as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_FSPs.shape[0]: 3476\n",
      "df_FSPs_final.shape[0]: 3085\n"
     ]
    }
   ],
   "source": [
    "print(\"df_FSPs.shape[0]:\",df_FSPs.shape[0])\n",
    "df_FSPs_final = df_FSPs[df_FSPs[\"Hc\"] == 0]\n",
    "print(\"df_FSPs_final.shape[0]:\",df_FSPs_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['__event__', 'B_tag_ID', 'B_sig_ID'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_Bs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['__experiment__', '__run__', '__event__', '__candidate__',\n",
       "       '__ncandidates__', '__weight__', 'basf2_X', 'basf2_used', 'basf2_Bsig',\n",
       "       'isSignal', 'uniqueParticleIdentifier', 'mcErrors', 'mcPDG',\n",
       "       'genMotherID', 'genMotherP', 'genMotherPDG', 'px', 'py', 'pz', 'pt',\n",
       "       'p', 'E', 'kaonID', 'pionID', 'genMothPDG_0', 'genMothPDG_1',\n",
       "       'genMothPDG_2', 'genMothPDG_3', 'genMothPDG_4', 'genMothPDG_5',\n",
       "       'genMothPDG_6', 'genMothPDG_7', 'genMothPDG_8', 'genMothPDG_9',\n",
       "       'mcMother0_uniqParID', 'mcMother1_uniqParID', 'mcMother2_uniqParID',\n",
       "       'mcMother3_uniqParID', 'mcMother4_uniqParID', 'mcMother5_uniqParID',\n",
       "       'mcMother6_uniqParID', 'mcMother7_uniqParID', 'mcMother8_uniqParID',\n",
       "       'mcMother9_uniqParID', 'PDG', 'B_ID', 'Hc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FSPs_final.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start of NN data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minFSPs: 17\n",
      "maxFSPs: 47 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-887bf7860262>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_FSPs_final['numFSPs'] = df_FSPs_final.groupby('__event__')['__event__'].transform('count')\n"
     ]
    }
   ],
   "source": [
    "numFSPs = pd.DataFrame({'count' : df_FSPs_final.groupby( [\"__event__\"] ).size()}).reset_index()\n",
    "\n",
    "minFSPs = numFSPs[\"count\"].min()\n",
    "maxFSPs = numFSPs[\"count\"].max()\n",
    "print(\"minFSPs:\",minFSPs)\n",
    "print(\"maxFSPs:\",maxFSPs,'\\n')\n",
    "\n",
    "df_FSPs_final['numFSPs'] = df_FSPs_final.groupby('__event__')['__event__'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save data to: /nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/NNdata/Dstlnu_Hc_corr_BsigX_separation_dataRun1/axheim_data2_MC14_100kEvts is True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(nfs_path + \"NNdata/\" + data_subdir + root_subdir)    \n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Will save data to:\", data_dir,'is', save_data ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numEvents: 1\n",
      "num_FSPs_toData: 17\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 0\n",
      "num_FSPs_toData: 18\n",
      "skipped because empty \n",
      "\n",
      "numEvents: 0\n",
      "num_FSPs_toData: 19\n",
      "skipped because empty \n",
      "\n",
      "numEvents: 2\n",
      "num_FSPs_toData: 20\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 0\n",
      "num_FSPs_toData: 21\n",
      "skipped because empty \n",
      "\n",
      "numEvents: 2\n",
      "num_FSPs_toData: 22\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 2\n",
      "num_FSPs_toData: 23\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 6\n",
      "num_FSPs_toData: 24\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 4\n",
      "num_FSPs_toData: 25\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 4\n",
      "num_FSPs_toData: 26\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 6\n",
      "num_FSPs_toData: 27\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 5\n",
      "num_FSPs_toData: 28\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 6\n",
      "num_FSPs_toData: 29\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 12\n",
      "num_FSPs_toData: 30\n",
      "leaves.shape: (12, 30, 4)\n",
      "SA_target.shape: (12, 30)\n",
      "global_tag.shape: (12, 31)\n",
      "leaves[0]: [[-1.12887910e-02 -3.29260081e-02  6.54010428e-03  3.54165466e-02]\n",
      " [-5.90942008e-03 -2.76641175e-02 -4.15659137e-02  5.02787214e-02]\n",
      " [ 8.23642761e-02  3.75533819e-01  4.80463564e-01  6.15349299e-01]\n",
      " [-1.52349076e-03  1.28668863e-02 -1.72406770e-02  2.15666115e-02]\n",
      " [-3.16504955e-01  1.02687836e+00 -2.24512145e-01  1.09775248e+00]\n",
      " [-2.30383903e-01  3.68639156e-02  1.07559711e-01  5.56526507e-01]\n",
      " [ 6.49849623e-02  5.04111350e-02  1.03558265e-01  1.32244630e-01]\n",
      " [-3.27493459e-01 -7.15992823e-02  2.97432363e-01  4.48156706e-01]\n",
      " [-2.26188614e-03 -9.12232231e-03 -1.77935027e-02  2.01231615e-02]\n",
      " [-9.88892280e-03  2.11482812e-02  1.01650483e-03  2.33682236e-02]\n",
      " [-5.99823780e-02 -6.01697247e-04  2.38709152e-02  1.53778935e-01]\n",
      " [ 3.98673750e-02 -1.68717187e-02  4.75800456e-03  4.35511319e-02]\n",
      " [ 7.07280487e-02 -4.85232333e-03 -8.43836665e-02  1.10211638e-01]\n",
      " [ 4.96207811e-02  8.04632232e-02  4.87053059e-02  1.06342649e-01]\n",
      " [ 9.97090526e-03  5.37502058e-02  1.08721815e-01  1.21691974e-01]\n",
      " [-1.92268610e-01 -2.50339359e-01  1.33043498e-01  3.42545742e-01]\n",
      " [ 3.46296638e-01 -5.42107895e-02  3.90858687e-02  3.52686655e-01]\n",
      " [-6.05303831e-02  1.21027942e-05  2.40903199e-02  1.54026502e-01]\n",
      " [ 6.46961629e-01 -6.04769170e-01  2.53850520e-01  9.31785961e-01]\n",
      " [ 2.08803833e-01  4.22423445e-02 -5.14350943e-02  2.19155253e-01]\n",
      " [-1.13846980e-01 -8.14652815e-03  3.50150645e-01  3.68283824e-01]\n",
      " [ 1.68222293e-01  1.20069496e-01  1.88543111e-01  2.79756910e-01]\n",
      " [-6.57029003e-02  1.90916006e-02 -1.35552481e-01  1.51841481e-01]\n",
      " [ 3.59112807e-02 -1.47507563e-01  2.19987690e-01  5.61390823e-01]\n",
      " [ 1.08018741e-02  9.25544873e-02  2.85880212e-02  9.74694237e-02]\n",
      " [ 1.11585751e-03  1.39898118e-02  2.32083071e-02  2.71216793e-02]\n",
      " [-3.79482716e-01 -1.18429914e-01 -4.24902439e-01  5.98376764e-01]\n",
      " [ 8.77487808e-02  8.72202292e-02  3.06166131e-02  1.27454282e-01]\n",
      " [-1.89097449e-02 -5.48804738e-02  5.28943576e-02  7.85318911e-02]\n",
      " [ 1.78844258e-01  1.16591491e-01  2.44121820e-01  3.24305885e-01]]\n",
      "SA_target[0]: [2. 0. 2. 0. 1. 2. 0. 2. 0. 0. 2. 2. 2. 2. 0. 2. 2. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 0. 2. 2. 2. 2.]\n",
      "global_tag[0]: [b'22.0_basf2_X' b'nan_basf2_bg' b'22.0_basf2_Bsig' b'nan_basf2_bg'\n",
      " b'-11.0_basf2_Bsig' b'-211.0_basf2_bg' b'nan_basf2_X' b'22.0_basf2_X'\n",
      " b'nan_basf2_bg' b'nan_basf2_bg' b'11.0_basf2_Bsig' b'22.0_basf2_X'\n",
      " b'22.0_basf2_X' b'22.0_basf2_Bsig' b'nan_basf2_X' b'22.0_basf2_bg'\n",
      " b'22.0_basf2_X' b'-11.0_basf2_bg' b'-211.0_basf2_X' b'22.0_basf2_X'\n",
      " b'22.0_basf2_X' b'22.0_basf2_X' b'211.0_basf2_X' b'211.0_basf2_Bsig'\n",
      " b'22.0_basf2_X' b'nan_basf2_bg' b'-211.0_basf2_Bsig' b'22.0_basf2_X'\n",
      " b'22.0_basf2_X' b'-211.0_basf2_bg' b'evt17457424']\n",
      "\n",
      "numEvents: 3\n",
      "num_FSPs_toData: 31\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 8\n",
      "num_FSPs_toData: 32\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 7\n",
      "num_FSPs_toData: 33\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 9\n",
      "num_FSPs_toData: 34\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 7\n",
      "num_FSPs_toData: 35\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 2\n",
      "num_FSPs_toData: 36\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 4\n",
      "num_FSPs_toData: 37\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 3\n",
      "num_FSPs_toData: 38\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 1\n",
      "num_FSPs_toData: 39\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 4\n",
      "num_FSPs_toData: 40\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 0\n",
      "num_FSPs_toData: 41\n",
      "skipped because empty \n",
      "\n",
      "numEvents: 0\n",
      "num_FSPs_toData: 42\n",
      "skipped because empty \n",
      "\n",
      "numEvents: 1\n",
      "num_FSPs_toData: 43\n",
      "skipped because <10 events \n",
      "\n",
      "numEvents: 0\n",
      "num_FSPs_toData: 44\n",
      "skipped because empty \n",
      "\n",
      "numEvents: 0\n",
      "num_FSPs_toData: 45\n",
      "skipped because empty \n",
      "\n",
      "numEvents: 0\n",
      "num_FSPs_toData: 46\n",
      "skipped because empty \n",
      "\n",
      "numEvents: 1\n",
      "num_FSPs_toData: 47\n",
      "skipped because <10 events \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_FSPs_toData in range(minFSPs, maxFSPs+1):\n",
    "    df_num_subset = df_FSPs_final.copy()\n",
    "    df_num_subset = df_num_subset[df_num_subset['numFSPs'] == num_FSPs_toData]\n",
    "    \n",
    "        \n",
    "    numEvents = df_num_subset.__event__.nunique()\n",
    "    print(\"numEvents:\",numEvents)\n",
    "    print(\"num_FSPs_toData:\",num_FSPs_toData)  \n",
    "    if numEvents == 0:\n",
    "        print(\"skipped because empty \\n\")\n",
    "        continue\n",
    "\n",
    "    if numEvents < 10:\n",
    "        print(\"skipped because <10 events \\n\")\n",
    "        continue\n",
    "    \n",
    "    num_features = 4\n",
    "    leaves = np.zeros((numEvents, num_FSPs_toData,  num_features))  \n",
    "    SA_target =  np.zeros((numEvents, num_FSPs_toData))\n",
    "    global_tag = np.chararray((numEvents, num_FSPs_toData + 1), itemsize=30)\n",
    "    \n",
    "    event_list = df_num_subset[df_num_subset[\"numFSPs\"] == num_FSPs_toData][\"__event__\"].unique()\n",
    "    #print(\"len(event_list):\",len(event_list))\n",
    "    for i in range(numEvents):\n",
    "\n",
    "        event_iter = event_list[i]\n",
    "\n",
    "        global_tag_masterInfo = \"evt\" + str(event_iter)\n",
    "        global_tag[i,-1] = global_tag_masterInfo\n",
    "        #print(\"global_tag[i,-1]:\",global_tag[i,-1])\n",
    "        #print(\"i:\",i,\"event_iter:\",event_iter)\n",
    "\n",
    "        event_df = df_num_subset[df_num_subset.__event__ == event_iter]\n",
    "\n",
    "        for j in range(num_FSPs_toData):\n",
    "            #print(\"numParticle:\",j)\n",
    "            particle = event_df.iloc[j]\n",
    "\n",
    "            #print(particle[\"mcPDG\"],particle[\"px\"],particle[\"py\"],particle[\"pz\"],particle[\"E\"])\n",
    "            leaves[i,j,0] = particle[\"px\"]\n",
    "            leaves[i,j,1] = particle[\"py\"]\n",
    "            leaves[i,j,2] = particle[\"pz\"]\n",
    "            leaves[i,j,3] = particle[\"E\"]\n",
    "            \n",
    "            basf2_usage = \"basf2_NONE\"\n",
    "            if particle[\"basf2_Bsig\"] == 1.0:\n",
    "                basf2_usage = \"basf2_Bsig\"\n",
    "            elif particle[\"basf2_X\"] == 1.0:\n",
    "                basf2_usage = \"basf2_X\"\n",
    "            elif particle[\"basf2_used\"] == 0:\n",
    "                basf2_usage = \"basf2_bg\"\n",
    "\n",
    "            global_tag_Info = str((particle[\"mcPDG\"])) \n",
    "            global_tag_Info += \"_\" + basf2_usage\n",
    "            global_tag[i,j] = global_tag_Info\n",
    "\n",
    "            label = -10 # error code if assignment fails\n",
    "            B_tag_uniqID = event_Bs[event_Bs.__event__ == event_iter].iloc[0]['B_tag_ID']\n",
    "            B_sig_uniqID = event_Bs[event_Bs.__event__ == event_iter].iloc[0]['B_sig_ID']\n",
    "            if particle[\"B_ID\"] == B_tag_uniqID:\n",
    "                label = 1 # particle belongs to X (MC truth)\n",
    "            elif particle[\"B_ID\"] == B_sig_uniqID:\n",
    "                label = 2 # particle belongs to Bsig (MC truth)\n",
    "            elif particle[\"B_ID\"] == 0:\n",
    "                label = 0 # background\n",
    "            \n",
    "            \n",
    "            SA_target[i,j] = label\n",
    "            \n",
    "        del event_df\n",
    "        \n",
    "        \n",
    "    # shuffle the data    \n",
    "    for idx in np.arange(leaves.shape[0]):   # arange is like range but gives ndarray instead of list\n",
    "        perms = np.random.permutation(leaves.shape[1])\n",
    "\n",
    "        leaves[idx,:] = leaves[idx,perms]\n",
    "        SA_target[idx,:] = SA_target[idx,perms]\n",
    "        global_tag[idx,0:-1] = global_tag[idx,perms]\n",
    "        \n",
    "        \n",
    "         \n",
    "\n",
    "\n",
    "    #print(global_tag)\n",
    "    train_ratio = 0.75\n",
    "    validation_ratio = 0.15\n",
    "    test_ratio = 0.10\n",
    "\n",
    "    print(\"leaves.shape:\",leaves.shape)\n",
    "    print(\"SA_target.shape:\",SA_target.shape)\n",
    "    print(\"global_tag.shape:\",global_tag.shape)\n",
    "\n",
    "\n",
    "    print(\"leaves[0]:\",leaves[0])\n",
    "    print(\"SA_target[0]:\",SA_target[0])\n",
    "    print(\"global_tag[0]:\",global_tag[0])\n",
    "\n",
    "    x=leaves\n",
    "    y=SA_target\n",
    "    z=global_tag\n",
    "\n",
    "    x_train, x_test, y_train, y_test, z_train, z_test = train_test_split(x, y, z, test_size=1 - train_ratio, shuffle=False)\n",
    "    x_val, x_test, y_val, y_test, z_val, z_test = train_test_split(x_test, y_test, z_test, test_size=test_ratio/(test_ratio + validation_ratio), shuffle=False) \n",
    "\n",
    "    if save_data==True:\n",
    "        np.save(data_dir / \"leaves_train_FSP{}.npy\".format(num_FSPs_toData), x_train)\n",
    "        np.save(data_dir / \"is_left_arr_train_FSP{}.npy\".format(num_FSPs_toData), y_train)\n",
    "        np.save(data_dir / \"global_tag_train_FSP{}.npy\".format(num_FSPs_toData), z_train)\n",
    "\n",
    "        np.save(data_dir / \"leaves_val_FSP{}.npy\".format(num_FSPs_toData), x_val)\n",
    "        np.save(data_dir / \"is_left_arr_val_FSP{}.npy\".format(num_FSPs_toData), y_val)\n",
    "        np.save(data_dir / \"global_tag_val_FSP{}.npy\".format(num_FSPs_toData), z_val)\n",
    "\n",
    "        np.save(data_dir / \"leaves_test_FSP{}.npy\".format(num_FSPs_toData), x_test)\n",
    "        np.save(data_dir / \"is_left_arr_test_FSP{}.npy\".format(num_FSPs_toData), y_test)\n",
    "        np.save(data_dir / \"global_tag_test_FSP{}.npy\".format(num_FSPs_toData), z_test)\n",
    "\n",
    "    \n",
    "    print(\"\")\n",
    "    #del df_num_subset\n",
    "\n",
    "\n",
    "    del df_num_subset\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving is done\n",
      "time at end = 2021-09-20 22:18:45.767296\n"
     ]
    }
   ],
   "source": [
    "print(\"saving is done\")\n",
    "now = datetime.now()\n",
    "print(\"time at end =\", now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
