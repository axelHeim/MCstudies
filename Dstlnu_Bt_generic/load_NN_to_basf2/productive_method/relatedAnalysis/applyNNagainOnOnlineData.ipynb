{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/afs/desy.de/user/a/axelheim/private/MC_studies/Dstlnu_Bt_generic/util_funcs/')\n",
    "from pandas_colFuncs import B_ID, whichBisSig, D0_decay_type, whichBisSig_NAHS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_vars = [\"px\",\"py\",\"pz\",\"E\",\"M\",\"charge\",\"dr\",\"dz\",\"clusterReg\",\"clusterE9E21\",\"pionID\",\"kaonID\",\"electronID\",\"muonID\",\"protonID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using factor graph MLP encoder.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('/afs/desy.de/user/a/axelheim/private/baumbauen/notebooks/')\n",
    "from BranchSeparatorModel import BranchSeparatorModel\n",
    "# See below why I put this\n",
    "\n",
    "\n",
    "\n",
    "model_dir=\"/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/saved_models/NAHSA_Gmodes_fixedD0modes/NAHS_allEvts_twoSubs_fixedD0run/NAHSA_no_xyz/256_0_64_0.1_4/\"\n",
    "checkpoint_name = \"model_checkpoint_model_perfectSA=0.7674.pt\"\n",
    "specs_output_label = \"256_0_64_0.1_4\"\n",
    "num_classes = 3    \n",
    "\n",
    "\n",
    "specs = specs_output_label.split(\"_\")\n",
    "\n",
    "model = BranchSeparatorModel(infeatures=len(nn_vars),\n",
    "            dim_feedforward=int(specs[0]),\n",
    "            num_classes=num_classes,\n",
    "            dropout=float(specs[3]),\n",
    "            nblocks=int(specs[4]))\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "checkpoint = torch.load(model_dir +  checkpoint_name, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the online data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs_path = \"/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/appliedNNdata/10thRun/\"\n",
    "#nfs_path=\"/afs/desy.de/user/a/axelheim/private/MC_studies/Dstlnu_Bt_generic/load_NN_to_basf2/productive_method/testOut/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSPs_file = uproot.open(nfs_path + \"FSPs.root:variables;1\")\n",
    "df_FSPs = FSPs_file.arrays(library=\"pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ups4S_file = uproot.open(nfs_path + \"Ups4S_NN_predicted.root:variables;1\")\n",
    "df_Ups4S = Ups4S_file.arrays(library=\"pd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FSPs['B_ID'] = df_FSPs.apply(B_ID, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hc_motherB_df = df_FSPs[df_FSPs[\"NN_prediction\"].isna() == True].drop_duplicates(subset=(\"__event__\"), keep='first')\n",
    "Hc_motherB_df[\"B_tag_ID\"] = Hc_motherB_df[\"B_ID\"]\n",
    "df_FSPs = pd.merge(df_FSPs,Hc_motherB_df[[\"__event__\",\"__production__\",\"B_tag_ID\"]], on=[\"__event__\",\"__production__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(s):\n",
    "    label = -1\n",
    "    if int(s['B_ID']) == 0:\n",
    "        label = 0 # background, cause not related to MC Particles\n",
    "    else: \n",
    "        B_tagID = s['B_tag_ID']\n",
    "        \n",
    "        if int(s['B_ID']) == B_tagID:\n",
    "            label = 1 # X\n",
    "        else:\n",
    "            label = 2 # Bsig\n",
    "    return label\n",
    "df_FSPs['label'] = df_FSPs.apply(labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FSPs[\"correct_pred_onlineNN\"] = (df_FSPs[\"label\"] == df_FSPs[\"NN_prediction\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503316"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FSPs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check DO decays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Ups4S['Bsig_uniqParID'] = df_Ups4S.apply(whichBisSig_NAHS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Ups4S['D0_decay'] = df_Ups4S.apply(D0_decay_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "notWanted     90057\n",
       "Kpipi0        16833\n",
       "Kpipipipi0    12039\n",
       "Kpipipi        8745\n",
       "Kpi            3508\n",
       "Name: D0_decay, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Ups4S['D0_decay'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Ups4S = df_Ups4S[df_Ups4S['D0_decay'] != \"notWanted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FSPs = df_FSPs[df_FSPs['__event__'].isin(df_Ups4S[\"__event__\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare input for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonHc_FSPs = df_FSPs[df_FSPs[\"NN_prediction\"].notna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    128494.000000\n",
       "mean          1.212033\n",
       "std           0.735228\n",
       "min           0.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max           2.000000\n",
       "Name: NN_prediction, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonHc_FSPs[\"NN_prediction\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128494"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonHc_FSPs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-83b3aaa500f8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nonHc_FSPs[\"offline_NN_pred\"] = -1\n",
      "<ipython-input-20-83b3aaa500f8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nonHc_FSPs[\"offline_NN_pred_shuffled\"] = -1\n"
     ]
    }
   ],
   "source": [
    "nonHc_FSPs[\"offline_NN_pred\"] = -1\n",
    "nonHc_FSPs[\"offline_NN_pred_shuffled\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evts = nonHc_FSPs[\"__event__\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8657\n"
     ]
    }
   ],
   "source": [
    "print(len(evts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2337804"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing evt 0 of 8657\n",
      "processing evt 100 of 8657\n",
      "processing evt 200 of 8657\n",
      "processing evt 300 of 8657\n",
      "processing evt 400 of 8657\n",
      "processing evt 500 of 8657\n",
      "processing evt 600 of 8657\n",
      "processing evt 700 of 8657\n",
      "processing evt 800 of 8657\n",
      "processing evt 900 of 8657\n",
      "processing evt 1000 of 8657\n",
      "processing evt 1100 of 8657\n",
      "processing evt 1200 of 8657\n",
      "processing evt 1300 of 8657\n",
      "processing evt 1400 of 8657\n",
      "processing evt 1500 of 8657\n",
      "processing evt 1600 of 8657\n",
      "processing evt 1700 of 8657\n",
      "processing evt 1800 of 8657\n",
      "processing evt 1900 of 8657\n",
      "processing evt 2000 of 8657\n",
      "processing evt 2100 of 8657\n",
      "processing evt 2200 of 8657\n",
      "processing evt 2300 of 8657\n",
      "processing evt 2400 of 8657\n",
      "processing evt 2500 of 8657\n",
      "processing evt 2600 of 8657\n",
      "processing evt 2700 of 8657\n",
      "processing evt 2800 of 8657\n",
      "processing evt 2900 of 8657\n",
      "processing evt 3000 of 8657\n",
      "processing evt 3100 of 8657\n",
      "processing evt 3200 of 8657\n",
      "processing evt 3300 of 8657\n",
      "processing evt 3400 of 8657\n",
      "processing evt 3500 of 8657\n",
      "processing evt 3600 of 8657\n",
      "processing evt 3700 of 8657\n",
      "processing evt 3800 of 8657\n",
      "processing evt 3900 of 8657\n",
      "processing evt 4000 of 8657\n",
      "processing evt 4100 of 8657\n",
      "processing evt 4200 of 8657\n",
      "processing evt 4300 of 8657\n",
      "processing evt 4400 of 8657\n",
      "processing evt 4500 of 8657\n",
      "processing evt 4600 of 8657\n",
      "processing evt 4700 of 8657\n",
      "processing evt 4800 of 8657\n",
      "processing evt 4900 of 8657\n",
      "processing evt 5000 of 8657\n",
      "processing evt 5100 of 8657\n",
      "processing evt 5200 of 8657\n",
      "processing evt 5300 of 8657\n",
      "processing evt 5400 of 8657\n",
      "processing evt 5500 of 8657\n",
      "processing evt 5600 of 8657\n",
      "processing evt 5700 of 8657\n",
      "processing evt 5800 of 8657\n",
      "processing evt 5900 of 8657\n",
      "processing evt 6000 of 8657\n",
      "processing evt 6100 of 8657\n",
      "processing evt 6200 of 8657\n",
      "processing evt 6300 of 8657\n",
      "processing evt 6400 of 8657\n",
      "processing evt 6500 of 8657\n",
      "processing evt 6600 of 8657\n",
      "processing evt 6700 of 8657\n",
      "processing evt 6800 of 8657\n",
      "processing evt 6900 of 8657\n",
      "processing evt 7000 of 8657\n",
      "processing evt 7100 of 8657\n",
      "processing evt 7200 of 8657\n",
      "processing evt 7300 of 8657\n",
      "processing evt 7400 of 8657\n",
      "processing evt 7500 of 8657\n",
      "processing evt 7600 of 8657\n",
      "processing evt 7700 of 8657\n",
      "processing evt 7800 of 8657\n",
      "processing evt 7900 of 8657\n",
      "processing evt 8000 of 8657\n",
      "processing evt 8100 of 8657\n",
      "processing evt 8200 of 8657\n",
      "processing evt 8300 of 8657\n",
      "processing evt 8400 of 8657\n",
      "processing evt 8500 of 8657\n",
      "processing evt 8600 of 8657\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "evtnum=[]\n",
    "online_NN_pred=[]\n",
    "offline_NN_pred=[]\n",
    "offline_NN_pred_shuff=[]\n",
    "\n",
    "for i in range(len(evts)):\n",
    "    one_evt = nonHc_FSPs[(nonHc_FSPs[\"__event__\"] == evts[i])]\n",
    "    \n",
    "    if (i % 100) == 0:\n",
    "        print(\"processing evt\",i,\"of\",len(evts))\n",
    "    \n",
    "    \n",
    "    num_particles = one_evt.shape[0]\n",
    "    \n",
    "    tmp_par_vars = []\n",
    "    \n",
    "    for j in range(num_particles):\n",
    "        particle = one_evt.iloc[j]\n",
    "        #print(particle)\n",
    "        readOut_features = [particle[var] for var in nn_vars]\n",
    "        tmp_par_vars.append(readOut_features)\n",
    "\n",
    "    NN_input_features = np.array([np.array(xi) for xi in tmp_par_vars])\n",
    "\n",
    "    # impute the nan values with -1. (check if that's logical for all values if input vars get changed)\n",
    "    NN_input_features= np.nan_to_num(NN_input_features, copy=False, nan=-1.0)\n",
    "\n",
    "    shape = NN_input_features.shape\n",
    "    NN_input_features = NN_input_features.reshape(shape[0], 1, shape[1])\n",
    "\n",
    "    #print(\"NN_input_features.shape:\",NN_input_features.shape)\n",
    "    NN_input_features = torch.Tensor(NN_input_features)\n",
    "    #print(NN_input_features.shape[0])\n",
    "\n",
    "    SA_pred = model(NN_input_features)\n",
    "\n",
    "    probs = torch.softmax(SA_pred, dim=1)  # (N, C, d1)\n",
    "    winners = probs.argmax(dim=1)\n",
    "    \n",
    "    \n",
    "    shape = NN_input_features.shape\n",
    "    r=torch.randperm(shape[0])\n",
    "    shuffled_input=NN_input_features[r, :, :]\n",
    "    \n",
    "    shuffled_SA_pred = model(shuffled_input)\n",
    "\n",
    "    shuffled_probs = torch.softmax(shuffled_SA_pred, dim=1)  # (N, C, d1)\n",
    "    shuffled_winners = shuffled_probs.argmax(dim=1)\n",
    "    #print(\"r:\",r)\n",
    "    for j in range(num_particles):\n",
    "        particle = one_evt.iloc[j]\n",
    "        labels.append(particle[\"label\"].item())\n",
    "        evtnum.append(particle[\"__event__\"].item())\n",
    "        online_NN_pred.append(particle[\"NN_prediction\"].item())\n",
    "        #particle[\"offline_NN_pred\"] = winners[0,j].item()\n",
    "        offline_NN_pred.append(winners[0,j].item())\n",
    "        \n",
    "        \n",
    "        index_Shuffreversed = (r == j).nonzero(as_tuple=True)[0].item()\n",
    "        #print(\"j:\",j,\"index_Shuffreversed:\",index_Shuffreversed)\n",
    "        offline_NN_pred_shuff.append(shuffled_winners[0,index_Shuffreversed].item())\n",
    "        \n",
    "        #particle[\"offline_NN_pred_shuffled\"] = shuffled_winners[0,index_Shuffreversed].item()\n",
    "        #one_evt.iloc[j] = particle\n",
    "        \n",
    "    #nonHc_FSPs[(nonHc_FSPs[\"__event__\"] == evts[i])] = one_evt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_results = pd.DataFrame({'__event__': evtnum,\n",
    "                          'label' : labels,\n",
    "                          'online_NN_pred' : online_NN_pred,\n",
    "                          'offline_NN_pred' : offline_NN_pred,\n",
    "                          'offline_NN_pred_shuff' : offline_NN_pred_shuff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_results.to_csv(nfs_path + \"NN_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_results = pd.read_csv(nfs_path + \"NN_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_results[\"off_eq_on\"] = (NN_results[\"offline_NN_pred\"] == NN_results[\"online_NN_pred\"]).astype(int)\n",
    "NN_results[\"off_eq_on_shuffled\"] = (NN_results[\"offline_NN_pred_shuff\"] == NN_results[\"online_NN_pred\"]).astype(int)\n",
    "NN_results[\"unshuff_eq_shuff\"] = (NN_results[\"offline_NN_pred_shuff\"] == NN_results[\"offline_NN_pred\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_results[\"correct_pred_onlineNN\"] = (NN_results[\"label\"] == NN_results[\"online_NN_pred\"]).astype(int)\n",
    "NN_results[\"correct_pred_offlineNN\"] = (NN_results[\"label\"] == NN_results[\"offline_NN_pred\"]).astype(int)\n",
    "NN_results[\"correct_pred_offlineNN_shuff\"] = (NN_results[\"label\"] == NN_results[\"offline_NN_pred_shuff\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off_eq_on\n",
      "80.1220290441577 % \n",
      "\n",
      "off_eq_on_shuffled\n",
      "80.0854514607686 % \n",
      "\n",
      "unshuff_eq_shuff\n",
      "82.43886874095288 % \n",
      "\n",
      "correct_pred_onlineNN\n",
      "67.37279561691597 % \n",
      "\n",
      "correct_pred_offlineNN\n",
      "64.2528055784706 % \n",
      "\n",
      "correct_pred_offlineNN_shuff\n",
      "64.15552477158467 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for var in [\"off_eq_on\",\"off_eq_on_shuffled\",\"unshuff_eq_shuff\",\"correct_pred_onlineNN\",\"correct_pred_offlineNN\",\"correct_pred_offlineNN_shuff\"]:\n",
    "    print(var)\n",
    "    print(NN_results[var].mean()*100, '% \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>off_eq_on</th>\n",
       "      <th>correct_pred_onlineNN</th>\n",
       "      <th>correct_pred_offlineNN</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   off_eq_on  correct_pred_onlineNN  correct_pred_offlineNN     count\n",
       "0          0                      0                       0  0.027511\n",
       "1          0                      0                       1  0.070034\n",
       "2          0                      1                       0  0.101234\n",
       "3          1                      0                       0  0.228727\n",
       "4          1                      1                       1  0.572494"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_on_pred = pd.DataFrame({'count' : NN_results.groupby( [\"off_eq_on\",\n",
    "                    \"correct_pred_onlineNN\",\"correct_pred_offlineNN\"] ).size() / NN_results.shape[0] }).reset_index()\n",
    "off_on_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare only the events used offline (val set) with the online results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"NAHSA_Gmodes_fixedD0modes/NAHS_allEvts_twoSubs_fixedD0run/NAHSA_no_xyz\"\n",
    "run_folder = \"MC_studies/Dstlnu_Bt_generic/\" #\"run_HcX_globTag/\" \n",
    "run_path = \"/nfs/dust/belle2/user/axelheim/\" + run_folder\n",
    "bsize = 16\n",
    "dataset_dir = Path(run_path + 'data/' + data_folder)\n",
    "\n",
    "\n",
    "sys.path.insert(1, '/afs/desy.de/user/a/axelheim/private/baumbauen/notebooks/')\n",
    "from ah_utils import pad_collate_fn_ah, PhasespaceSet_BranchSeparator\n",
    "\n",
    "collate = pad_collate_fn_ah\n",
    "test_set = PhasespaceSet_BranchSeparator(dataset_dir, 'val')\n",
    "train_set = PhasespaceSet_BranchSeparator(dataset_dir, 'train')\n",
    "import torch\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=bsize, drop_last=True, shuffle=True,  collate_fn=collate)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=bsize, drop_last=True, shuffle=True,  collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "evts_train=[]\n",
    "for batch_num, batch in enumerate(dataiter):\n",
    "    features, labels, tag = batch\n",
    "    tag = np.array(tag)\n",
    "    for i in range(tag.shape[0]):\n",
    "        tag_tmp = str(tag[i,-1])\n",
    "        event = int(tag_tmp[tag_tmp.find(\"evt\")+3:-1])\n",
    "        evts_train.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 of 3367 batches\n",
      "# 10 of 3367 batches\n",
      "# 20 of 3367 batches\n",
      "# 30 of 3367 batches\n",
      "# 40 of 3367 batches\n",
      "# 50 of 3367 batches\n",
      "# 60 of 3367 batches\n",
      "# 70 of 3367 batches\n",
      "# 80 of 3367 batches\n",
      "# 90 of 3367 batches\n",
      "# 100 of 3367 batches\n",
      "# 110 of 3367 batches\n",
      "# 120 of 3367 batches\n",
      "# 130 of 3367 batches\n",
      "# 140 of 3367 batches\n",
      "# 150 of 3367 batches\n",
      "# 160 of 3367 batches\n",
      "# 170 of 3367 batches\n",
      "# 180 of 3367 batches\n",
      "# 190 of 3367 batches\n",
      "# 200 of 3367 batches\n",
      "# 210 of 3367 batches\n",
      "# 220 of 3367 batches\n",
      "# 230 of 3367 batches\n",
      "# 240 of 3367 batches\n",
      "# 250 of 3367 batches\n",
      "# 260 of 3367 batches\n",
      "# 270 of 3367 batches\n",
      "# 280 of 3367 batches\n",
      "# 290 of 3367 batches\n",
      "# 300 of 3367 batches\n",
      "# 310 of 3367 batches\n",
      "# 320 of 3367 batches\n",
      "# 330 of 3367 batches\n",
      "# 340 of 3367 batches\n",
      "# 350 of 3367 batches\n",
      "# 360 of 3367 batches\n",
      "# 370 of 3367 batches\n",
      "# 380 of 3367 batches\n",
      "# 390 of 3367 batches\n",
      "# 400 of 3367 batches\n",
      "# 410 of 3367 batches\n",
      "# 420 of 3367 batches\n",
      "# 430 of 3367 batches\n",
      "# 440 of 3367 batches\n",
      "# 450 of 3367 batches\n",
      "# 460 of 3367 batches\n",
      "# 470 of 3367 batches\n",
      "# 480 of 3367 batches\n",
      "# 490 of 3367 batches\n",
      "# 500 of 3367 batches\n",
      "# 510 of 3367 batches\n",
      "# 520 of 3367 batches\n",
      "# 530 of 3367 batches\n",
      "# 540 of 3367 batches\n",
      "# 550 of 3367 batches\n",
      "# 560 of 3367 batches\n",
      "# 570 of 3367 batches\n",
      "# 580 of 3367 batches\n",
      "# 590 of 3367 batches\n",
      "# 600 of 3367 batches\n",
      "# 610 of 3367 batches\n",
      "# 620 of 3367 batches\n",
      "# 630 of 3367 batches\n",
      "# 640 of 3367 batches\n",
      "# 650 of 3367 batches\n",
      "# 660 of 3367 batches\n",
      "# 670 of 3367 batches\n",
      "# 680 of 3367 batches\n",
      "# 690 of 3367 batches\n",
      "# 700 of 3367 batches\n",
      "# 710 of 3367 batches\n",
      "# 720 of 3367 batches\n",
      "# 730 of 3367 batches\n",
      "# 740 of 3367 batches\n",
      "# 750 of 3367 batches\n",
      "# 760 of 3367 batches\n",
      "# 770 of 3367 batches\n",
      "# 780 of 3367 batches\n",
      "# 790 of 3367 batches\n",
      "# 800 of 3367 batches\n",
      "# 810 of 3367 batches\n",
      "# 820 of 3367 batches\n",
      "# 830 of 3367 batches\n",
      "# 840 of 3367 batches\n",
      "# 850 of 3367 batches\n",
      "# 860 of 3367 batches\n",
      "# 870 of 3367 batches\n",
      "# 880 of 3367 batches\n",
      "# 890 of 3367 batches\n",
      "# 900 of 3367 batches\n",
      "# 910 of 3367 batches\n",
      "# 920 of 3367 batches\n",
      "# 930 of 3367 batches\n",
      "# 940 of 3367 batches\n",
      "# 950 of 3367 batches\n",
      "# 960 of 3367 batches\n",
      "# 970 of 3367 batches\n",
      "# 980 of 3367 batches\n",
      "# 990 of 3367 batches\n",
      "# 1000 of 3367 batches\n",
      "# 1010 of 3367 batches\n",
      "# 1020 of 3367 batches\n",
      "# 1030 of 3367 batches\n",
      "# 1040 of 3367 batches\n",
      "# 1050 of 3367 batches\n",
      "# 1060 of 3367 batches\n",
      "# 1070 of 3367 batches\n",
      "# 1080 of 3367 batches\n",
      "# 1090 of 3367 batches\n",
      "# 1100 of 3367 batches\n",
      "# 1110 of 3367 batches\n",
      "# 1120 of 3367 batches\n",
      "# 1130 of 3367 batches\n",
      "# 1140 of 3367 batches\n",
      "# 1150 of 3367 batches\n",
      "# 1160 of 3367 batches\n",
      "# 1170 of 3367 batches\n",
      "# 1180 of 3367 batches\n",
      "# 1190 of 3367 batches\n",
      "# 1200 of 3367 batches\n",
      "# 1210 of 3367 batches\n",
      "# 1220 of 3367 batches\n",
      "# 1230 of 3367 batches\n",
      "# 1240 of 3367 batches\n",
      "# 1250 of 3367 batches\n",
      "# 1260 of 3367 batches\n",
      "# 1270 of 3367 batches\n",
      "# 1280 of 3367 batches\n",
      "# 1290 of 3367 batches\n",
      "# 1300 of 3367 batches\n",
      "# 1310 of 3367 batches\n",
      "# 1320 of 3367 batches\n",
      "# 1330 of 3367 batches\n",
      "# 1340 of 3367 batches\n",
      "# 1350 of 3367 batches\n",
      "# 1360 of 3367 batches\n",
      "# 1370 of 3367 batches\n",
      "# 1380 of 3367 batches\n",
      "# 1390 of 3367 batches\n",
      "# 1400 of 3367 batches\n",
      "# 1410 of 3367 batches\n",
      "# 1420 of 3367 batches\n",
      "# 1430 of 3367 batches\n",
      "# 1440 of 3367 batches\n",
      "# 1450 of 3367 batches\n",
      "# 1460 of 3367 batches\n",
      "# 1470 of 3367 batches\n",
      "# 1480 of 3367 batches\n",
      "# 1490 of 3367 batches\n",
      "# 1500 of 3367 batches\n",
      "# 1510 of 3367 batches\n",
      "# 1520 of 3367 batches\n",
      "# 1530 of 3367 batches\n",
      "# 1540 of 3367 batches\n",
      "# 1550 of 3367 batches\n",
      "# 1560 of 3367 batches\n",
      "# 1570 of 3367 batches\n",
      "# 1580 of 3367 batches\n",
      "# 1590 of 3367 batches\n",
      "# 1600 of 3367 batches\n",
      "# 1610 of 3367 batches\n",
      "# 1620 of 3367 batches\n",
      "# 1630 of 3367 batches\n",
      "# 1640 of 3367 batches\n",
      "# 1650 of 3367 batches\n",
      "# 1660 of 3367 batches\n",
      "# 1670 of 3367 batches\n",
      "# 1680 of 3367 batches\n",
      "# 1690 of 3367 batches\n",
      "# 1700 of 3367 batches\n",
      "# 1710 of 3367 batches\n",
      "# 1720 of 3367 batches\n",
      "# 1730 of 3367 batches\n",
      "# 1740 of 3367 batches\n",
      "# 1750 of 3367 batches\n",
      "# 1760 of 3367 batches\n",
      "# 1770 of 3367 batches\n",
      "# 1780 of 3367 batches\n",
      "# 1790 of 3367 batches\n",
      "# 1800 of 3367 batches\n",
      "# 1810 of 3367 batches\n",
      "# 1820 of 3367 batches\n",
      "# 1830 of 3367 batches\n",
      "# 1840 of 3367 batches\n",
      "# 1850 of 3367 batches\n",
      "# 1860 of 3367 batches\n",
      "# 1870 of 3367 batches\n",
      "# 1880 of 3367 batches\n",
      "# 1890 of 3367 batches\n",
      "# 1900 of 3367 batches\n",
      "# 1910 of 3367 batches\n",
      "# 1920 of 3367 batches\n",
      "# 1930 of 3367 batches\n",
      "# 1940 of 3367 batches\n",
      "# 1950 of 3367 batches\n",
      "# 1960 of 3367 batches\n",
      "# 1970 of 3367 batches\n",
      "# 1980 of 3367 batches\n",
      "# 1990 of 3367 batches\n",
      "# 2000 of 3367 batches\n",
      "# 2010 of 3367 batches\n",
      "# 2020 of 3367 batches\n",
      "# 2030 of 3367 batches\n",
      "# 2040 of 3367 batches\n",
      "# 2050 of 3367 batches\n",
      "# 2060 of 3367 batches\n",
      "# 2070 of 3367 batches\n",
      "# 2080 of 3367 batches\n",
      "# 2090 of 3367 batches\n",
      "# 2100 of 3367 batches\n",
      "# 2110 of 3367 batches\n",
      "# 2120 of 3367 batches\n",
      "# 2130 of 3367 batches\n",
      "# 2140 of 3367 batches\n",
      "# 2150 of 3367 batches\n",
      "# 2160 of 3367 batches\n",
      "# 2170 of 3367 batches\n",
      "# 2180 of 3367 batches\n",
      "# 2190 of 3367 batches\n",
      "# 2200 of 3367 batches\n",
      "# 2210 of 3367 batches\n",
      "# 2220 of 3367 batches\n",
      "# 2230 of 3367 batches\n",
      "# 2240 of 3367 batches\n",
      "# 2250 of 3367 batches\n",
      "# 2260 of 3367 batches\n",
      "# 2270 of 3367 batches\n",
      "# 2280 of 3367 batches\n",
      "# 2290 of 3367 batches\n",
      "# 2300 of 3367 batches\n",
      "# 2310 of 3367 batches\n",
      "# 2320 of 3367 batches\n",
      "# 2330 of 3367 batches\n",
      "# 2340 of 3367 batches\n",
      "# 2350 of 3367 batches\n",
      "# 2360 of 3367 batches\n",
      "# 2370 of 3367 batches\n",
      "# 2380 of 3367 batches\n",
      "# 2390 of 3367 batches\n",
      "# 2400 of 3367 batches\n",
      "# 2410 of 3367 batches\n",
      "# 2420 of 3367 batches\n",
      "# 2430 of 3367 batches\n",
      "# 2440 of 3367 batches\n",
      "# 2450 of 3367 batches\n",
      "# 2460 of 3367 batches\n",
      "# 2470 of 3367 batches\n",
      "# 2480 of 3367 batches\n",
      "# 2490 of 3367 batches\n",
      "# 2500 of 3367 batches\n",
      "# 2510 of 3367 batches\n",
      "# 2520 of 3367 batches\n",
      "# 2530 of 3367 batches\n",
      "# 2540 of 3367 batches\n",
      "# 2550 of 3367 batches\n",
      "# 2560 of 3367 batches\n",
      "# 2570 of 3367 batches\n",
      "# 2580 of 3367 batches\n",
      "# 2590 of 3367 batches\n",
      "# 2600 of 3367 batches\n",
      "# 2610 of 3367 batches\n",
      "# 2620 of 3367 batches\n",
      "# 2630 of 3367 batches\n",
      "# 2640 of 3367 batches\n",
      "# 2650 of 3367 batches\n",
      "# 2660 of 3367 batches\n",
      "# 2670 of 3367 batches\n",
      "# 2680 of 3367 batches\n",
      "# 2690 of 3367 batches\n",
      "# 2700 of 3367 batches\n",
      "# 2710 of 3367 batches\n",
      "# 2720 of 3367 batches\n",
      "# 2730 of 3367 batches\n",
      "# 2740 of 3367 batches\n",
      "# 2750 of 3367 batches\n",
      "# 2760 of 3367 batches\n",
      "# 2770 of 3367 batches\n",
      "# 2780 of 3367 batches\n",
      "# 2790 of 3367 batches\n",
      "# 2800 of 3367 batches\n",
      "# 2810 of 3367 batches\n",
      "# 2820 of 3367 batches\n",
      "# 2830 of 3367 batches\n",
      "# 2840 of 3367 batches\n",
      "# 2850 of 3367 batches\n",
      "# 2860 of 3367 batches\n",
      "# 2870 of 3367 batches\n",
      "# 2880 of 3367 batches\n",
      "# 2890 of 3367 batches\n",
      "# 2900 of 3367 batches\n",
      "# 2910 of 3367 batches\n",
      "# 2920 of 3367 batches\n",
      "# 2930 of 3367 batches\n",
      "# 2940 of 3367 batches\n",
      "# 2950 of 3367 batches\n",
      "# 2960 of 3367 batches\n",
      "# 2970 of 3367 batches\n",
      "# 2980 of 3367 batches\n",
      "# 2990 of 3367 batches\n",
      "# 3000 of 3367 batches\n",
      "# 3010 of 3367 batches\n",
      "# 3020 of 3367 batches\n",
      "# 3030 of 3367 batches\n",
      "# 3040 of 3367 batches\n",
      "# 3050 of 3367 batches\n",
      "# 3060 of 3367 batches\n",
      "# 3070 of 3367 batches\n",
      "# 3080 of 3367 batches\n",
      "# 3090 of 3367 batches\n",
      "# 3100 of 3367 batches\n",
      "# 3110 of 3367 batches\n",
      "# 3120 of 3367 batches\n",
      "# 3130 of 3367 batches\n",
      "# 3140 of 3367 batches\n",
      "# 3150 of 3367 batches\n",
      "# 3160 of 3367 batches\n",
      "# 3170 of 3367 batches\n",
      "# 3180 of 3367 batches\n",
      "# 3190 of 3367 batches\n",
      "# 3200 of 3367 batches\n",
      "# 3210 of 3367 batches\n",
      "# 3220 of 3367 batches\n",
      "# 3230 of 3367 batches\n",
      "# 3240 of 3367 batches\n",
      "# 3250 of 3367 batches\n",
      "# 3260 of 3367 batches\n",
      "# 3270 of 3367 batches\n",
      "# 3280 of 3367 batches\n",
      "# 3290 of 3367 batches\n",
      "# 3300 of 3367 batches\n",
      "# 3310 of 3367 batches\n",
      "# 3320 of 3367 batches\n",
      "# 3330 of 3367 batches\n",
      "# 3340 of 3367 batches\n",
      "# 3350 of 3367 batches\n",
      "# 3360 of 3367 batches\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "evts=[]\n",
    "preds=[]\n",
    "labs=[]\n",
    "corrects=[]\n",
    "\n",
    "for batch_num, batch in enumerate(dataiter):\n",
    "    if batch_num % 10 == 0:\n",
    "        print(\"#\",(batch_num),\"of\",len(test_loader),\"batches\")\n",
    "    features, labels, tag = batch\n",
    "    tag = np.array(tag)\n",
    "    \n",
    "    SA_pred = model(features)\n",
    "\n",
    "    probs = torch.softmax(SA_pred, dim=1)  # (N, C, d1)\n",
    "    winners = probs.argmax(dim=1)\n",
    "    #print(\"winners.shape:\",winners.shape)\n",
    "    #print(\"labels.shape:\",labels.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(winners.shape[0]):\n",
    "        tag_tmp = str(tag[i,-1])\n",
    "        event = int(tag_tmp[tag_tmp.find(\"evt\")+3:-1])\n",
    "        #print(\"winners[i,:]:\",winners[i,:])\n",
    "        #print(\"labels[i,:]:\",labels[i,:])\n",
    "        for j in range(winners.shape[1]):\n",
    "            evts.append(event)\n",
    "\n",
    "            pred = winners[i,j].item()\n",
    "            preds.append(pred)\n",
    "            \n",
    "            label = labels[i,j].item()\n",
    "            labs.append(label)\n",
    "            \n",
    "            #print(\"label:\",label,\"winners:\",pred)\n",
    "            \n",
    "            correct = int(label == pred)\n",
    "            corrects.append(correct)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_padded = pd.DataFrame({\"event\":evts, \"label\":labs,\"prediction\":preds,\"correct\":corrects})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of padded entries\n",
    "offline_preds_padded = offline_preds_padded[offline_preds_padded[\"label\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695854"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_preds_padded.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   695854.000\n",
       "mean         0.750\n",
       "std          0.433\n",
       "min          0.000\n",
       "25%          1.000\n",
       "50%          1.000\n",
       "75%          1.000\n",
       "max          1.000\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "offline_preds_padded[\"correct\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_and_offline = NN_results[NN_results['__event__'].isin(evts)]\n",
    "on_and_offline_train = NN_results[NN_results['__event__'].isin(evts_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098\n",
      "5344\n"
     ]
    }
   ],
   "source": [
    "print(on_and_offline['__event__'].nunique())\n",
    "print(on_and_offline_train['__event__'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off_eq_on\n",
      "80.1220290441577 %\n",
      "81.84001921691089 %\n",
      "81.19207115502164 % \n",
      "\n",
      "off_eq_on_shuffled\n",
      "80.0854514607686 %\n",
      "81.70790295460006 %\n",
      "81.09476940733256 % \n",
      "\n",
      "unshuff_eq_shuff\n",
      "82.43886874095288 %\n",
      "83.4854672111458 %\n",
      "83.38635031124085 % \n",
      "\n",
      "correct_pred_onlineNN\n",
      "67.37279561691597 %\n",
      "69.54720153735286 %\n",
      "70.48887890922246 % \n",
      "\n",
      "correct_pred_offlineNN\n",
      "64.2528055784706 %\n",
      "67.12106653855393 %\n",
      "67.62720956052044 % \n",
      "\n",
      "correct_pred_offlineNN_shuff\n",
      "64.15552477158467 %\n",
      "67.15709824645688 %\n",
      "67.65091126829086 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for var in [\"off_eq_on\",\"off_eq_on_shuffled\",\"unshuff_eq_shuff\",\"correct_pred_onlineNN\",\"correct_pred_offlineNN\",\"correct_pred_offlineNN_shuff\"]:\n",
    "    print(var)\n",
    "    print(NN_results[var].mean()*100, '%')    \n",
    "    print(on_and_offline[var].mean()*100, '%')    \n",
    "    print(on_and_offline_train[var].mean()*100, '% \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do offline padded again BUT with bsize = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BranchSeparatorModel(\n",
       "  (initial_mlp): Sequential(\n",
       "    (0): MLP(\n",
       "      (fc1): Linear(in_features=15, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (mlp2): MLP(\n",
       "    (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): MLP(\n",
       "        (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): MLP(\n",
       "        (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): MLP(\n",
       "        (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): MLP(\n",
       "        (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 of 53877 batches\n",
      "# 1000 of 53877 batches\n",
      "# 2000 of 53877 batches\n",
      "# 3000 of 53877 batches\n",
      "# 4000 of 53877 batches\n",
      "# 5000 of 53877 batches\n",
      "# 6000 of 53877 batches\n",
      "# 7000 of 53877 batches\n",
      "# 8000 of 53877 batches\n",
      "# 9000 of 53877 batches\n",
      "# 10000 of 53877 batches\n",
      "# 11000 of 53877 batches\n",
      "# 12000 of 53877 batches\n",
      "# 13000 of 53877 batches\n",
      "# 14000 of 53877 batches\n",
      "# 15000 of 53877 batches\n",
      "# 16000 of 53877 batches\n",
      "# 17000 of 53877 batches\n",
      "# 18000 of 53877 batches\n",
      "# 19000 of 53877 batches\n",
      "# 20000 of 53877 batches\n",
      "# 21000 of 53877 batches\n",
      "# 22000 of 53877 batches\n",
      "# 23000 of 53877 batches\n",
      "# 24000 of 53877 batches\n",
      "# 25000 of 53877 batches\n",
      "# 26000 of 53877 batches\n",
      "# 27000 of 53877 batches\n",
      "# 28000 of 53877 batches\n",
      "# 29000 of 53877 batches\n",
      "# 30000 of 53877 batches\n",
      "# 31000 of 53877 batches\n",
      "# 32000 of 53877 batches\n",
      "# 33000 of 53877 batches\n",
      "# 34000 of 53877 batches\n",
      "# 35000 of 53877 batches\n",
      "# 36000 of 53877 batches\n",
      "# 37000 of 53877 batches\n",
      "# 38000 of 53877 batches\n",
      "# 39000 of 53877 batches\n",
      "# 40000 of 53877 batches\n",
      "# 41000 of 53877 batches\n",
      "# 42000 of 53877 batches\n",
      "# 43000 of 53877 batches\n",
      "# 44000 of 53877 batches\n",
      "# 45000 of 53877 batches\n",
      "# 46000 of 53877 batches\n",
      "# 47000 of 53877 batches\n",
      "# 48000 of 53877 batches\n",
      "# 49000 of 53877 batches\n",
      "# 50000 of 53877 batches\n",
      "# 51000 of 53877 batches\n",
      "# 52000 of 53877 batches\n",
      "# 53000 of 53877 batches\n"
     ]
    }
   ],
   "source": [
    "test_loader_b1 = torch.utils.data.DataLoader(test_set, batch_size=1, drop_last=True, shuffle=True,  collate_fn=collate)\n",
    "dataiter = iter(test_loader_b1)\n",
    "evts=[]\n",
    "preds=[]\n",
    "labs=[]\n",
    "corrects=[]\n",
    "\n",
    "for batch_num, batch in enumerate(dataiter):\n",
    "    if batch_num % 1000 == 0:\n",
    "        print(\"#\",(batch_num),\"of\",len(test_loader_b1),\"batches\")\n",
    "    features, labels, tag = batch\n",
    "    tag = np.array(tag)\n",
    "    shape = features.shape\n",
    "    pad_dim = 22\n",
    "    num_particles = shape[0]\n",
    "    pad_input = (num_particles < pad_dim)\n",
    "    #print(\"features.shape:\",features.shape)\n",
    "\n",
    "    # padd_array is needed if padding is done, but needs to be initialized outside of the if clause\n",
    "    N = pad_dim \n",
    "    K = pad_dim - num_particles # K zeros, N-K ones\n",
    "    padd_array = np.array([0] * K + [1] * (N-K))\n",
    "    np.random.shuffle(padd_array)\n",
    "    #print(padd_array)\n",
    "\n",
    "\n",
    "    #print(\"pad_input:\",pad_input)\n",
    "    if pad_input:\n",
    "        #print(\"in pad_input:   num_particles:\", num_particles)\n",
    "\n",
    "\n",
    "        torch.set_printoptions(threshold=10_000)        \n",
    "        #print(\"shuffled_input:\",) # prints the whole tensor\n",
    "\n",
    "        input_padded = torch.ones(pad_dim, 1, shape[2]) * 0.\n",
    "        \n",
    "        #print(\"input_padded.shape:\",input_padded.shape)\n",
    "        #print(\"features.shape:\",features.shape)\n",
    "        \n",
    "        particle_counter = 0\n",
    "        for i in range(pad_dim):\n",
    "            do_pad = padd_array[i]\n",
    "            if do_pad == 1:    \n",
    "                #print(i)\n",
    "                #print(x[particle_counter,:,:])\n",
    "                input_padded[i,:,:] = features[particle_counter,:,:]\n",
    "                particle_counter += 1\n",
    "\n",
    "        #print(input_padded)\n",
    "        features = input_padded\n",
    "    \n",
    "    \n",
    "    SA_pred = model(features)\n",
    "\n",
    "    probs = torch.softmax(SA_pred, dim=1)  # (N, C, d1)\n",
    "    winners = probs.argmax(dim=1)\n",
    "    #print(\"winners.shape:\",winners.shape)\n",
    "    #print(\"winners:\",winners)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # unpad winners if pad_input\n",
    "    if pad_input:\n",
    "        winners_unpadded = torch.empty(1, num_particles)\n",
    "        particle_counter = 0\n",
    "        for i in range(pad_dim):\n",
    "            do_pad = padd_array[i]\n",
    "            if do_pad == 1:  \n",
    "                winners_unpadded[0, particle_counter] = winners[0, i]\n",
    "                particle_counter += 1\n",
    "\n",
    "        #print(winners_unpadded)\n",
    "\n",
    "        winners=winners_unpadded\n",
    "\n",
    "    #print(\"winners.shape:\",winners.shape)\n",
    "    #print(\"winners:\",winners)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(winners.shape[0]):\n",
    "        tag_tmp = str(tag[i,-1])\n",
    "        event = int(tag_tmp[tag_tmp.find(\"evt\")+3:-1])\n",
    "        #print(\"winners[i,:]:\",winners[i,:])\n",
    "        #print(\"labels[i,:]:\",labels[i,:])\n",
    "        for j in range(winners.shape[1]):\n",
    "            evts.append(event)\n",
    "\n",
    "            pred = winners[i,j].item()\n",
    "            preds.append(pred)\n",
    "            \n",
    "            label = labels[i,j].item()\n",
    "            labs.append(label)\n",
    "            \n",
    "            #print(\"label:\",label,\"winners:\",pred)\n",
    "            \n",
    "            correct = int(label == pred)\n",
    "            corrects.append(correct)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_padded_b1_eval = pd.DataFrame({\"event\":evts, \"label\":labs,\"prediction\":preds,\"correct\":corrects})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7630609400370727"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_preds_padded_b1_eval[\"correct\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695930"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_preds_padded_b1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of padded entries\n",
    "offline_preds_padded_b1 = offline_preds_padded_b1[offline_preds_padded_b1[\"label\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695930"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_preds_padded_b1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   695930.000\n",
       "mean         0.664\n",
       "std          0.472\n",
       "min          0.000\n",
       "25%          0.000\n",
       "50%          1.000\n",
       "75%          1.000\n",
       "max          1.000\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "offline_preds_padded_b1[\"correct\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check results for different batch sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 of 3367 batches\n",
      "# 10 of 3367 batches\n",
      "# 20 of 3367 batches\n",
      "# 30 of 3367 batches\n",
      "# 40 of 3367 batches\n",
      "# 50 of 3367 batches\n",
      "# 60 of 3367 batches\n",
      "# 70 of 3367 batches\n",
      "# 80 of 3367 batches\n",
      "# 90 of 3367 batches\n",
      "# 100 of 3367 batches\n",
      "# 110 of 3367 batches\n",
      "# 120 of 3367 batches\n",
      "# 130 of 3367 batches\n",
      "# 140 of 3367 batches\n",
      "# 150 of 3367 batches\n",
      "# 160 of 3367 batches\n",
      "# 170 of 3367 batches\n",
      "# 180 of 3367 batches\n",
      "# 190 of 3367 batches\n",
      "# 200 of 3367 batches\n",
      "# 210 of 3367 batches\n",
      "# 220 of 3367 batches\n",
      "# 230 of 3367 batches\n",
      "# 240 of 3367 batches\n",
      "# 250 of 3367 batches\n",
      "# 260 of 3367 batches\n",
      "# 270 of 3367 batches\n",
      "# 280 of 3367 batches\n",
      "# 290 of 3367 batches\n",
      "# 300 of 3367 batches\n",
      "# 310 of 3367 batches\n",
      "# 320 of 3367 batches\n",
      "# 330 of 3367 batches\n",
      "# 340 of 3367 batches\n",
      "# 350 of 3367 batches\n",
      "# 360 of 3367 batches\n",
      "# 370 of 3367 batches\n",
      "# 380 of 3367 batches\n",
      "# 390 of 3367 batches\n",
      "# 400 of 3367 batches\n",
      "# 410 of 3367 batches\n",
      "# 420 of 3367 batches\n",
      "# 430 of 3367 batches\n",
      "# 440 of 3367 batches\n",
      "# 450 of 3367 batches\n",
      "# 460 of 3367 batches\n",
      "# 470 of 3367 batches\n",
      "# 480 of 3367 batches\n",
      "# 490 of 3367 batches\n",
      "# 500 of 3367 batches\n",
      "# 510 of 3367 batches\n",
      "# 520 of 3367 batches\n",
      "# 530 of 3367 batches\n",
      "# 540 of 3367 batches\n",
      "# 550 of 3367 batches\n",
      "# 560 of 3367 batches\n",
      "# 570 of 3367 batches\n",
      "# 580 of 3367 batches\n",
      "# 590 of 3367 batches\n",
      "# 600 of 3367 batches\n",
      "# 610 of 3367 batches\n",
      "# 620 of 3367 batches\n",
      "# 630 of 3367 batches\n",
      "# 640 of 3367 batches\n",
      "# 650 of 3367 batches\n",
      "# 660 of 3367 batches\n",
      "# 670 of 3367 batches\n",
      "# 680 of 3367 batches\n",
      "# 690 of 3367 batches\n",
      "# 700 of 3367 batches\n",
      "# 710 of 3367 batches\n",
      "# 720 of 3367 batches\n",
      "# 730 of 3367 batches\n",
      "# 740 of 3367 batches\n",
      "# 750 of 3367 batches\n",
      "# 760 of 3367 batches\n",
      "# 770 of 3367 batches\n",
      "# 780 of 3367 batches\n",
      "# 790 of 3367 batches\n",
      "# 800 of 3367 batches\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-f7fa208ebb77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mSA_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSA_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (N, C, d1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/private/baumbauen/notebooks/BranchSeparatorModel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode2edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_send\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l*l, 2d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l*l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# Skip connection to jump over all NRI blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/private/baumbauen/src/baumbauen/layers/mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for bsize in [16,64,128]:\n",
    "    test_loader_var = torch.utils.data.DataLoader(test_set, batch_size=bsize, drop_last=True, shuffle=True,  collate_fn=collate)\n",
    "    dataiter = iter(test_loader_var)\n",
    "    evts=[]\n",
    "    preds=[]\n",
    "    labs=[]\n",
    "    corrects=[]\n",
    "\n",
    "    for batch_num, batch in enumerate(dataiter):\n",
    "        if batch_num % 10 == 0:\n",
    "            print(\"#\",(batch_num),\"of\",len(test_loader_var),\"batches\")\n",
    "        features, labels, tag = batch\n",
    "        tag = np.array(tag)\n",
    "\n",
    "        SA_pred = model(features)\n",
    "\n",
    "        probs = torch.softmax(SA_pred, dim=1)  # (N, C, d1)\n",
    "        winners = probs.argmax(dim=1)\n",
    "        #print(\"winners.shape:\",winners.shape)\n",
    "        #print(\"labels.shape:\",labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(winners.shape[0]):\n",
    "            tag_tmp = str(tag[i,-1])\n",
    "            event = int(tag_tmp[tag_tmp.find(\"evt\")+3:-1])\n",
    "            #print(\"winners[i,:]:\",winners[i,:])\n",
    "            #print(\"labels[i,:]:\",labels[i,:])\n",
    "            for j in range(winners.shape[1]):\n",
    "                evts.append(event)\n",
    "\n",
    "                pred = winners[i,j].item()\n",
    "                preds.append(pred)\n",
    "\n",
    "                label = labels[i,j].item()\n",
    "                labs.append(label)\n",
    "\n",
    "                #print(\"label:\",label,\"winners:\",pred)\n",
    "\n",
    "                correct = int(label == pred)\n",
    "                corrects.append(correct)\n",
    "\n",
    "    offline_preds_padded_var = pd.DataFrame({\"event\":evts, \"label\":labs,\"prediction\":preds,\"correct\":corrects})\n",
    "    print(offline_preds_padded_var.shape[0])    \n",
    "    offline_preds_padded_var = offline_preds_padded_var[offline_preds_padded_var[\"label\"] != -1]\n",
    "    print(offline_preds_padded_var.shape[0])\n",
    "    print(offline_preds_padded_var[\"correct\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## turn batchnorm off and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " batchnorm=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do it again with offline, but unpadded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize = 1\n",
    "test_loader_unpadded = torch.utils.data.DataLoader(test_set, batch_size=bsize, drop_last=True, shuffle=True,  collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 of 53877 batches\n",
      "# 1000 of 53877 batches\n",
      "# 2000 of 53877 batches\n",
      "# 3000 of 53877 batches\n",
      "# 4000 of 53877 batches\n",
      "# 5000 of 53877 batches\n",
      "# 6000 of 53877 batches\n",
      "# 7000 of 53877 batches\n",
      "# 8000 of 53877 batches\n",
      "# 9000 of 53877 batches\n",
      "# 10000 of 53877 batches\n",
      "# 11000 of 53877 batches\n",
      "# 12000 of 53877 batches\n",
      "# 13000 of 53877 batches\n",
      "# 14000 of 53877 batches\n",
      "# 15000 of 53877 batches\n",
      "# 16000 of 53877 batches\n",
      "# 17000 of 53877 batches\n",
      "# 18000 of 53877 batches\n",
      "# 19000 of 53877 batches\n",
      "# 20000 of 53877 batches\n",
      "# 21000 of 53877 batches\n",
      "# 22000 of 53877 batches\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-05fd99ba6ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mSA_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSA_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (N, C, d1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/private/baumbauen/notebooks/BranchSeparatorModel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mx_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# (b, l*l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge2node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_rec\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode2edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_send\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l*l, 2d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Skip connection  # (b, l*l, 3d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/private/baumbauen/src/baumbauen/layers/mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/private/baumbauen/src/baumbauen/layers/mlp.py\u001b[0m in \u001b[0;36mbatch_norm_layer\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbatch_norm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2149\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2150\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader_unpadded)\n",
    "evts=[]\n",
    "preds=[]\n",
    "labs=[]\n",
    "corrects=[]\n",
    "\n",
    "for batch_num, batch in enumerate(dataiter):\n",
    "    if batch_num % 1000 == 0:\n",
    "        print(\"#\",(batch_num),\"of\",len(test_loader_unpadded),\"batches\")\n",
    "    features, labels, tag = batch\n",
    "    tag = np.array(tag)\n",
    "    \n",
    "    SA_pred = model(features)\n",
    "\n",
    "    probs = torch.softmax(SA_pred, dim=1)  # (N, C, d1)\n",
    "    winners = probs.argmax(dim=1)\n",
    "    #print(\"winners.shape:\",winners.shape)\n",
    "    #print(\"labels.shape:\",labels.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(winners.shape[0]):\n",
    "        tag_tmp = str(tag[i,-1])\n",
    "        event = int(tag_tmp[tag_tmp.find(\"evt\")+3:-1])\n",
    "        #print(\"winners[i,:]:\",winners[i,:])\n",
    "        #print(\"labels[i,:]:\",labels[i,:])\n",
    "        for j in range(winners.shape[1]):\n",
    "            evts.append(event)\n",
    "\n",
    "            pred = winners[i,j].item()\n",
    "            preds.append(pred)\n",
    "            \n",
    "            label = labels[i,j].item()\n",
    "            labs.append(label)\n",
    "            \n",
    "            #print(\"label:\",label,\"winners:\",pred)\n",
    "            \n",
    "            correct = int(label == pred)\n",
    "            corrects.append(correct)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_unpadded = pd.DataFrame({\"event\":evts, \"label\":labs,\"prediction\":preds,\"correct\":corrects})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_unpadded[\"correct\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_padded.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_padded[\"correct\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_padded.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs_path = \"/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/appliedNNdata/10thRun/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save offline padded/unpadded results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_unpadded.to_csv(nfs_path + \"offline_preds_unpadded.csv\")\n",
    "offline_preds_padded.to_csv(nfs_path + \"offline_preds_padded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load offline padded/unpadded results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_unpadded = pd.read_csv(nfs_path + \"offline_preds_unpadded.csv\")\n",
    "offline_preds_padded = pd.read_csv(nfs_path + \"offline_preds_padded.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
