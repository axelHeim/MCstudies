{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/afs/desy.de/user/a/axelheim/private/MC_studies/Dstlnu_Bt_generic/util_funcs/')\n",
    "from pandas_colFuncs import B_ID, whichBisSig, D0_decay_type, whichBisSig_NAHS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_vars = [\"px\",\"py\",\"pz\",\"E\",\"M\",\"charge\",\"dr\",\"dz\",\"clusterReg\",\"clusterE9E21\",\"pionID\",\"kaonID\",\"electronID\",\"muonID\",\"protonID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using factor graph MLP encoder.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('/afs/desy.de/user/a/axelheim/private/baumbauen/notebooks/')\n",
    "from BranchSeparatorModel import BranchSeparatorModel\n",
    "# See below why I put this\n",
    "\n",
    "\n",
    "\n",
    "model_dir=\"/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/saved_models/NAHSA_Gmodes_fixedD0modes/NAHS_allEvts_twoSubs_fixedD0run/NAHSA_no_xyz/256_0_64_0.1_4/\"\n",
    "checkpoint_name = \"model_checkpoint_model_perfectSA=0.7674.pt\"\n",
    "specs_output_label = \"256_0_64_0.1_4\"\n",
    "num_classes = 3    \n",
    "\n",
    "\n",
    "specs = specs_output_label.split(\"_\")\n",
    "\n",
    "model = BranchSeparatorModel(infeatures=len(nn_vars),\n",
    "            dim_feedforward=int(specs[0]),\n",
    "            num_classes=num_classes,\n",
    "            dropout=float(specs[3]),\n",
    "            nblocks=int(specs[4]))\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "checkpoint = torch.load(model_dir +  checkpoint_name, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the online data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs_path = \"/nfs/dust/belle2/user/axelheim/MC_studies/Dstlnu_Bt_generic/appliedNNdata/8thRun/\"\n",
    "#nfs_path=\"/afs/desy.de/user/a/axelheim/private/MC_studies/Dstlnu_Bt_generic/load_NN_to_basf2/productive_method/testOut/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSPs_file = uproot.open(nfs_path + \"FSPs.root:variables;1\")\n",
    "df_FSPs = FSPs_file.arrays(library=\"pd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FSPs['B_ID'] = df_FSPs.apply(B_ID, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hc_motherB_df = df_FSPs[df_FSPs[\"NN_prediction\"].isna() == True].drop_duplicates(subset=(\"__event__\"), keep='first')\n",
    "Hc_motherB_df[\"B_tag_ID\"] = Hc_motherB_df[\"B_ID\"]\n",
    "df_FSPs = pd.merge(df_FSPs,Hc_motherB_df[[\"__event__\",\"__production__\",\"B_tag_ID\"]], on=[\"__event__\",\"__production__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(s):\n",
    "    label = -1\n",
    "    if int(s['B_ID']) == 0:\n",
    "        label = 0 # background, cause not related to MC Particles\n",
    "    else: \n",
    "        B_tagID = s['B_tag_ID']\n",
    "        \n",
    "        if int(s['B_ID']) == B_tagID:\n",
    "            label = 1 # X\n",
    "        else:\n",
    "            label = 2 # Bsig\n",
    "    return label\n",
    "df_FSPs['label'] = df_FSPs.apply(labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FSPs[\"correct_pred_onlineNN\"] = (df_FSPs[\"label\"] == df_FSPs[\"NN_prediction\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848135"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FSPs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare input for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonHc_FSPs = df_FSPs[df_FSPs[\"NN_prediction\"].notna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    702287.000000\n",
       "mean          1.159428\n",
       "std           0.760966\n",
       "min           0.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max           2.000000\n",
       "Name: NN_prediction, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonHc_FSPs[\"NN_prediction\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702287"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonHc_FSPs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-83b3aaa500f8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nonHc_FSPs[\"offline_NN_pred\"] = -1\n",
      "<ipython-input-14-83b3aaa500f8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nonHc_FSPs[\"offline_NN_pred_shuffled\"] = -1\n"
     ]
    }
   ],
   "source": [
    "nonHc_FSPs[\"offline_NN_pred\"] = -1\n",
    "nonHc_FSPs[\"offline_NN_pred_shuffled\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "evts = nonHc_FSPs[\"__event__\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44945\n"
     ]
    }
   ],
   "source": [
    "print(len(evts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2336782"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing evt 0 of 44945\n",
      "processing evt 100 of 44945\n",
      "processing evt 200 of 44945\n",
      "processing evt 300 of 44945\n",
      "processing evt 400 of 44945\n",
      "processing evt 500 of 44945\n",
      "processing evt 600 of 44945\n",
      "processing evt 700 of 44945\n",
      "processing evt 800 of 44945\n",
      "processing evt 900 of 44945\n",
      "processing evt 1000 of 44945\n",
      "processing evt 1100 of 44945\n",
      "processing evt 1200 of 44945\n",
      "processing evt 1300 of 44945\n",
      "processing evt 1400 of 44945\n",
      "processing evt 1500 of 44945\n",
      "processing evt 1600 of 44945\n",
      "processing evt 1700 of 44945\n",
      "processing evt 1800 of 44945\n",
      "processing evt 1900 of 44945\n",
      "processing evt 2000 of 44945\n",
      "processing evt 2100 of 44945\n",
      "processing evt 2200 of 44945\n",
      "processing evt 2300 of 44945\n",
      "processing evt 2400 of 44945\n",
      "processing evt 2500 of 44945\n",
      "processing evt 2600 of 44945\n",
      "processing evt 2700 of 44945\n",
      "processing evt 2800 of 44945\n",
      "processing evt 2900 of 44945\n",
      "processing evt 3000 of 44945\n",
      "processing evt 3100 of 44945\n",
      "processing evt 3200 of 44945\n",
      "processing evt 3300 of 44945\n",
      "processing evt 3400 of 44945\n",
      "processing evt 3500 of 44945\n",
      "processing evt 3600 of 44945\n",
      "processing evt 3700 of 44945\n",
      "processing evt 3800 of 44945\n",
      "processing evt 3900 of 44945\n",
      "processing evt 4000 of 44945\n",
      "processing evt 4100 of 44945\n",
      "processing evt 4200 of 44945\n",
      "processing evt 4300 of 44945\n",
      "processing evt 4400 of 44945\n",
      "processing evt 4500 of 44945\n",
      "processing evt 4600 of 44945\n",
      "processing evt 4700 of 44945\n",
      "processing evt 4800 of 44945\n",
      "processing evt 4900 of 44945\n",
      "processing evt 5000 of 44945\n",
      "processing evt 5100 of 44945\n",
      "processing evt 5200 of 44945\n",
      "processing evt 5300 of 44945\n",
      "processing evt 5400 of 44945\n",
      "processing evt 5500 of 44945\n",
      "processing evt 5600 of 44945\n",
      "processing evt 5700 of 44945\n",
      "processing evt 5800 of 44945\n",
      "processing evt 5900 of 44945\n",
      "processing evt 6000 of 44945\n",
      "processing evt 6100 of 44945\n",
      "processing evt 6200 of 44945\n",
      "processing evt 6300 of 44945\n",
      "processing evt 6400 of 44945\n",
      "processing evt 6500 of 44945\n",
      "processing evt 6600 of 44945\n",
      "processing evt 6700 of 44945\n",
      "processing evt 6800 of 44945\n",
      "processing evt 6900 of 44945\n",
      "processing evt 7000 of 44945\n",
      "processing evt 7100 of 44945\n",
      "processing evt 7200 of 44945\n",
      "processing evt 7300 of 44945\n",
      "processing evt 7400 of 44945\n",
      "processing evt 7500 of 44945\n",
      "processing evt 7600 of 44945\n",
      "processing evt 7700 of 44945\n",
      "processing evt 7800 of 44945\n",
      "processing evt 7900 of 44945\n",
      "processing evt 8000 of 44945\n",
      "processing evt 8100 of 44945\n",
      "processing evt 8200 of 44945\n",
      "processing evt 8300 of 44945\n",
      "processing evt 8400 of 44945\n",
      "processing evt 8500 of 44945\n",
      "processing evt 8600 of 44945\n",
      "processing evt 8700 of 44945\n",
      "processing evt 8800 of 44945\n",
      "processing evt 8900 of 44945\n",
      "processing evt 9000 of 44945\n",
      "processing evt 9100 of 44945\n",
      "processing evt 9200 of 44945\n",
      "processing evt 9300 of 44945\n",
      "processing evt 9400 of 44945\n",
      "processing evt 9500 of 44945\n",
      "processing evt 9600 of 44945\n",
      "processing evt 9700 of 44945\n",
      "processing evt 9800 of 44945\n",
      "processing evt 9900 of 44945\n",
      "processing evt 10000 of 44945\n",
      "processing evt 10100 of 44945\n",
      "processing evt 10200 of 44945\n",
      "processing evt 10300 of 44945\n",
      "processing evt 10400 of 44945\n",
      "processing evt 10500 of 44945\n",
      "processing evt 10600 of 44945\n",
      "processing evt 10700 of 44945\n",
      "processing evt 10800 of 44945\n",
      "processing evt 10900 of 44945\n",
      "processing evt 11000 of 44945\n",
      "processing evt 11100 of 44945\n",
      "processing evt 11200 of 44945\n",
      "processing evt 11300 of 44945\n",
      "processing evt 11400 of 44945\n",
      "processing evt 11500 of 44945\n",
      "processing evt 11600 of 44945\n",
      "processing evt 11700 of 44945\n",
      "processing evt 11800 of 44945\n",
      "processing evt 11900 of 44945\n",
      "processing evt 12000 of 44945\n",
      "processing evt 12100 of 44945\n",
      "processing evt 12200 of 44945\n",
      "processing evt 12300 of 44945\n",
      "processing evt 12400 of 44945\n",
      "processing evt 12500 of 44945\n",
      "processing evt 12600 of 44945\n",
      "processing evt 12700 of 44945\n",
      "processing evt 12800 of 44945\n",
      "processing evt 12900 of 44945\n",
      "processing evt 13000 of 44945\n",
      "processing evt 13100 of 44945\n",
      "processing evt 13200 of 44945\n",
      "processing evt 13300 of 44945\n",
      "processing evt 13400 of 44945\n",
      "processing evt 13500 of 44945\n",
      "processing evt 13600 of 44945\n",
      "processing evt 13700 of 44945\n",
      "processing evt 13800 of 44945\n",
      "processing evt 13900 of 44945\n",
      "processing evt 14000 of 44945\n",
      "processing evt 14100 of 44945\n",
      "processing evt 14200 of 44945\n",
      "processing evt 14300 of 44945\n",
      "processing evt 14400 of 44945\n",
      "processing evt 14500 of 44945\n",
      "processing evt 14600 of 44945\n",
      "processing evt 14700 of 44945\n",
      "processing evt 14800 of 44945\n",
      "processing evt 14900 of 44945\n",
      "processing evt 15000 of 44945\n",
      "processing evt 15100 of 44945\n",
      "processing evt 15200 of 44945\n",
      "processing evt 15300 of 44945\n",
      "processing evt 15400 of 44945\n",
      "processing evt 15500 of 44945\n",
      "processing evt 15600 of 44945\n",
      "processing evt 15700 of 44945\n",
      "processing evt 15800 of 44945\n",
      "processing evt 15900 of 44945\n",
      "processing evt 16000 of 44945\n",
      "processing evt 16100 of 44945\n",
      "processing evt 16200 of 44945\n",
      "processing evt 16300 of 44945\n",
      "processing evt 16400 of 44945\n",
      "processing evt 16500 of 44945\n",
      "processing evt 16600 of 44945\n",
      "processing evt 16700 of 44945\n",
      "processing evt 16800 of 44945\n",
      "processing evt 16900 of 44945\n",
      "processing evt 17000 of 44945\n",
      "processing evt 17100 of 44945\n",
      "processing evt 17200 of 44945\n",
      "processing evt 17300 of 44945\n",
      "processing evt 17400 of 44945\n",
      "processing evt 17500 of 44945\n",
      "processing evt 17600 of 44945\n",
      "processing evt 17700 of 44945\n",
      "processing evt 17800 of 44945\n",
      "processing evt 17900 of 44945\n",
      "processing evt 18000 of 44945\n",
      "processing evt 18100 of 44945\n",
      "processing evt 18200 of 44945\n",
      "processing evt 18300 of 44945\n",
      "processing evt 18400 of 44945\n",
      "processing evt 18500 of 44945\n",
      "processing evt 18600 of 44945\n",
      "processing evt 18700 of 44945\n",
      "processing evt 18800 of 44945\n",
      "processing evt 18900 of 44945\n",
      "processing evt 19000 of 44945\n",
      "processing evt 19100 of 44945\n",
      "processing evt 19200 of 44945\n",
      "processing evt 19300 of 44945\n",
      "processing evt 19400 of 44945\n",
      "processing evt 19500 of 44945\n",
      "processing evt 19600 of 44945\n",
      "processing evt 19700 of 44945\n",
      "processing evt 19800 of 44945\n",
      "processing evt 19900 of 44945\n",
      "processing evt 20000 of 44945\n",
      "processing evt 20100 of 44945\n",
      "processing evt 20200 of 44945\n",
      "processing evt 20300 of 44945\n",
      "processing evt 20400 of 44945\n",
      "processing evt 20500 of 44945\n",
      "processing evt 20600 of 44945\n",
      "processing evt 20700 of 44945\n",
      "processing evt 20800 of 44945\n",
      "processing evt 20900 of 44945\n",
      "processing evt 21000 of 44945\n",
      "processing evt 21100 of 44945\n",
      "processing evt 21200 of 44945\n",
      "processing evt 21300 of 44945\n",
      "processing evt 21400 of 44945\n",
      "processing evt 21500 of 44945\n",
      "processing evt 21600 of 44945\n",
      "processing evt 21700 of 44945\n",
      "processing evt 21800 of 44945\n",
      "processing evt 21900 of 44945\n",
      "processing evt 22000 of 44945\n",
      "processing evt 22100 of 44945\n",
      "processing evt 22200 of 44945\n",
      "processing evt 22300 of 44945\n",
      "processing evt 22400 of 44945\n",
      "processing evt 22500 of 44945\n",
      "processing evt 22600 of 44945\n",
      "processing evt 22700 of 44945\n",
      "processing evt 22800 of 44945\n",
      "processing evt 22900 of 44945\n",
      "processing evt 23000 of 44945\n",
      "processing evt 23100 of 44945\n",
      "processing evt 23200 of 44945\n",
      "processing evt 23300 of 44945\n",
      "processing evt 23400 of 44945\n",
      "processing evt 23500 of 44945\n",
      "processing evt 23600 of 44945\n",
      "processing evt 23700 of 44945\n",
      "processing evt 23800 of 44945\n",
      "processing evt 23900 of 44945\n",
      "processing evt 24000 of 44945\n",
      "processing evt 24100 of 44945\n",
      "processing evt 24200 of 44945\n",
      "processing evt 24300 of 44945\n",
      "processing evt 24400 of 44945\n",
      "processing evt 24500 of 44945\n",
      "processing evt 24600 of 44945\n",
      "processing evt 24700 of 44945\n",
      "processing evt 24800 of 44945\n",
      "processing evt 24900 of 44945\n",
      "processing evt 25000 of 44945\n",
      "processing evt 25100 of 44945\n",
      "processing evt 25200 of 44945\n",
      "processing evt 25300 of 44945\n",
      "processing evt 25400 of 44945\n",
      "processing evt 25500 of 44945\n",
      "processing evt 25600 of 44945\n",
      "processing evt 25700 of 44945\n",
      "processing evt 25800 of 44945\n",
      "processing evt 25900 of 44945\n",
      "processing evt 26000 of 44945\n",
      "processing evt 26100 of 44945\n",
      "processing evt 26200 of 44945\n",
      "processing evt 26300 of 44945\n",
      "processing evt 26400 of 44945\n",
      "processing evt 26500 of 44945\n",
      "processing evt 26600 of 44945\n",
      "processing evt 26700 of 44945\n",
      "processing evt 26800 of 44945\n",
      "processing evt 26900 of 44945\n",
      "processing evt 27000 of 44945\n",
      "processing evt 27100 of 44945\n",
      "processing evt 27200 of 44945\n",
      "processing evt 27300 of 44945\n",
      "processing evt 27400 of 44945\n",
      "processing evt 27500 of 44945\n",
      "processing evt 27600 of 44945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing evt 27700 of 44945\n",
      "processing evt 27800 of 44945\n",
      "processing evt 27900 of 44945\n",
      "processing evt 28000 of 44945\n",
      "processing evt 28100 of 44945\n",
      "processing evt 28200 of 44945\n",
      "processing evt 28300 of 44945\n",
      "processing evt 28400 of 44945\n",
      "processing evt 28500 of 44945\n",
      "processing evt 28600 of 44945\n",
      "processing evt 28700 of 44945\n",
      "processing evt 28800 of 44945\n",
      "processing evt 28900 of 44945\n",
      "processing evt 29000 of 44945\n",
      "processing evt 29100 of 44945\n",
      "processing evt 29200 of 44945\n",
      "processing evt 29300 of 44945\n",
      "processing evt 29400 of 44945\n",
      "processing evt 29500 of 44945\n",
      "processing evt 29600 of 44945\n",
      "processing evt 29700 of 44945\n",
      "processing evt 29800 of 44945\n",
      "processing evt 29900 of 44945\n",
      "processing evt 30000 of 44945\n",
      "processing evt 30100 of 44945\n",
      "processing evt 30200 of 44945\n",
      "processing evt 30300 of 44945\n",
      "processing evt 30400 of 44945\n",
      "processing evt 30500 of 44945\n",
      "processing evt 30600 of 44945\n",
      "processing evt 30700 of 44945\n",
      "processing evt 30800 of 44945\n",
      "processing evt 30900 of 44945\n",
      "processing evt 31000 of 44945\n",
      "processing evt 31100 of 44945\n",
      "processing evt 31200 of 44945\n",
      "processing evt 31300 of 44945\n",
      "processing evt 31400 of 44945\n",
      "processing evt 31500 of 44945\n",
      "processing evt 31600 of 44945\n",
      "processing evt 31700 of 44945\n",
      "processing evt 31800 of 44945\n",
      "processing evt 31900 of 44945\n",
      "processing evt 32000 of 44945\n",
      "processing evt 32100 of 44945\n",
      "processing evt 32200 of 44945\n",
      "processing evt 32300 of 44945\n",
      "processing evt 32400 of 44945\n",
      "processing evt 32500 of 44945\n",
      "processing evt 32600 of 44945\n",
      "processing evt 32700 of 44945\n",
      "processing evt 32800 of 44945\n",
      "processing evt 32900 of 44945\n",
      "processing evt 33000 of 44945\n",
      "processing evt 33100 of 44945\n",
      "processing evt 33200 of 44945\n",
      "processing evt 33300 of 44945\n",
      "processing evt 33400 of 44945\n",
      "processing evt 33500 of 44945\n",
      "processing evt 33600 of 44945\n",
      "processing evt 33700 of 44945\n",
      "processing evt 33800 of 44945\n",
      "processing evt 33900 of 44945\n",
      "processing evt 34000 of 44945\n",
      "processing evt 34100 of 44945\n",
      "processing evt 34200 of 44945\n",
      "processing evt 34300 of 44945\n",
      "processing evt 34400 of 44945\n",
      "processing evt 34500 of 44945\n",
      "processing evt 34600 of 44945\n",
      "processing evt 34700 of 44945\n",
      "processing evt 34800 of 44945\n",
      "processing evt 34900 of 44945\n",
      "processing evt 35000 of 44945\n",
      "processing evt 35100 of 44945\n",
      "processing evt 35200 of 44945\n",
      "processing evt 35300 of 44945\n",
      "processing evt 35400 of 44945\n",
      "processing evt 35500 of 44945\n",
      "processing evt 35600 of 44945\n",
      "processing evt 35700 of 44945\n",
      "processing evt 35800 of 44945\n",
      "processing evt 35900 of 44945\n",
      "processing evt 36000 of 44945\n",
      "processing evt 36100 of 44945\n",
      "processing evt 36200 of 44945\n",
      "processing evt 36300 of 44945\n",
      "processing evt 36400 of 44945\n",
      "processing evt 36500 of 44945\n",
      "processing evt 36600 of 44945\n",
      "processing evt 36700 of 44945\n",
      "processing evt 36800 of 44945\n",
      "processing evt 36900 of 44945\n",
      "processing evt 37000 of 44945\n",
      "processing evt 37100 of 44945\n",
      "processing evt 37200 of 44945\n",
      "processing evt 37300 of 44945\n",
      "processing evt 37400 of 44945\n",
      "processing evt 37500 of 44945\n",
      "processing evt 37600 of 44945\n",
      "processing evt 37700 of 44945\n",
      "processing evt 37800 of 44945\n",
      "processing evt 37900 of 44945\n",
      "processing evt 38000 of 44945\n",
      "processing evt 38100 of 44945\n",
      "processing evt 38200 of 44945\n",
      "processing evt 38300 of 44945\n",
      "processing evt 38400 of 44945\n",
      "processing evt 38500 of 44945\n",
      "processing evt 38600 of 44945\n",
      "processing evt 38700 of 44945\n",
      "processing evt 38800 of 44945\n",
      "processing evt 38900 of 44945\n",
      "processing evt 39000 of 44945\n",
      "processing evt 39100 of 44945\n",
      "processing evt 39200 of 44945\n",
      "processing evt 39300 of 44945\n",
      "processing evt 39400 of 44945\n",
      "processing evt 39500 of 44945\n",
      "processing evt 39600 of 44945\n",
      "processing evt 39700 of 44945\n",
      "processing evt 39800 of 44945\n",
      "processing evt 39900 of 44945\n",
      "processing evt 40000 of 44945\n",
      "processing evt 40100 of 44945\n",
      "processing evt 40200 of 44945\n",
      "processing evt 40300 of 44945\n",
      "processing evt 40400 of 44945\n",
      "processing evt 40500 of 44945\n",
      "processing evt 40600 of 44945\n",
      "processing evt 40700 of 44945\n",
      "processing evt 40800 of 44945\n",
      "processing evt 40900 of 44945\n",
      "processing evt 41000 of 44945\n",
      "processing evt 41100 of 44945\n",
      "processing evt 41200 of 44945\n",
      "processing evt 41300 of 44945\n",
      "processing evt 41400 of 44945\n",
      "processing evt 41500 of 44945\n",
      "processing evt 41600 of 44945\n",
      "processing evt 41700 of 44945\n",
      "processing evt 41800 of 44945\n",
      "processing evt 41900 of 44945\n",
      "processing evt 42000 of 44945\n",
      "processing evt 42100 of 44945\n",
      "processing evt 42200 of 44945\n",
      "processing evt 42300 of 44945\n",
      "processing evt 42400 of 44945\n",
      "processing evt 42500 of 44945\n",
      "processing evt 42600 of 44945\n",
      "processing evt 42700 of 44945\n",
      "processing evt 42800 of 44945\n",
      "processing evt 42900 of 44945\n",
      "processing evt 43000 of 44945\n",
      "processing evt 43100 of 44945\n",
      "processing evt 43200 of 44945\n",
      "processing evt 43300 of 44945\n",
      "processing evt 43400 of 44945\n",
      "processing evt 43500 of 44945\n",
      "processing evt 43600 of 44945\n",
      "processing evt 43700 of 44945\n",
      "processing evt 43800 of 44945\n",
      "processing evt 43900 of 44945\n",
      "processing evt 44000 of 44945\n",
      "processing evt 44100 of 44945\n",
      "processing evt 44200 of 44945\n",
      "processing evt 44300 of 44945\n",
      "processing evt 44400 of 44945\n",
      "processing evt 44500 of 44945\n",
      "processing evt 44600 of 44945\n",
      "processing evt 44700 of 44945\n",
      "processing evt 44800 of 44945\n",
      "processing evt 44900 of 44945\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "evtnum=[]\n",
    "online_NN_pred=[]\n",
    "offline_NN_pred=[]\n",
    "offline_NN_pred_shuff=[]\n",
    "\n",
    "for i in range(len(evts)):\n",
    "    one_evt = nonHc_FSPs[(nonHc_FSPs[\"__event__\"] == evts[i])]\n",
    "    \n",
    "    if (i % 100) == 0:\n",
    "        print(\"processing evt\",i,\"of\",len(evts))\n",
    "    \n",
    "    \n",
    "    num_particles = one_evt.shape[0]\n",
    "    \n",
    "    tmp_par_vars = []\n",
    "    \n",
    "    for j in range(num_particles):\n",
    "        particle = one_evt.iloc[j]\n",
    "        #print(particle)\n",
    "        readOut_features = [particle[var] for var in nn_vars]\n",
    "        tmp_par_vars.append(readOut_features)\n",
    "\n",
    "    NN_input_features = np.array([np.array(xi) for xi in tmp_par_vars])\n",
    "\n",
    "    # impute the nan values with -1. (check if that's logical for all values if input vars get changed)\n",
    "    NN_input_features= np.nan_to_num(NN_input_features, copy=False, nan=-1.0)\n",
    "\n",
    "    shape = NN_input_features.shape\n",
    "    NN_input_features = NN_input_features.reshape(shape[0], 1, shape[1])\n",
    "\n",
    "    #print(\"NN_input_features.shape:\",NN_input_features.shape)\n",
    "    NN_input_features = torch.Tensor(NN_input_features)\n",
    "    #print(NN_input_features.shape[0])\n",
    "\n",
    "    SA_pred = model(NN_input_features)\n",
    "\n",
    "    probs = torch.softmax(SA_pred, dim=1)  # (N, C, d1)\n",
    "    winners = probs.argmax(dim=1)\n",
    "    \n",
    "    \n",
    "    shape = NN_input_features.shape\n",
    "    r=torch.randperm(shape[0])\n",
    "    shuffled_input=NN_input_features[r, :, :]\n",
    "    \n",
    "    shuffled_SA_pred = model(shuffled_input)\n",
    "\n",
    "    shuffled_probs = torch.softmax(shuffled_SA_pred, dim=1)  # (N, C, d1)\n",
    "    shuffled_winners = shuffled_probs.argmax(dim=1)\n",
    "    #print(\"r:\",r)\n",
    "    for j in range(num_particles):\n",
    "        particle = one_evt.iloc[j]\n",
    "        labels.append(particle[\"label\"].item())\n",
    "        evtnum.append(particle[\"__event__\"].item())\n",
    "        online_NN_pred.append(particle[\"NN_prediction\"].item())\n",
    "        #particle[\"offline_NN_pred\"] = winners[0,j].item()\n",
    "        offline_NN_pred.append(winners[0,j].item())\n",
    "        \n",
    "        \n",
    "        index_Shuffreversed = (r == j).nonzero(as_tuple=True)[0].item()\n",
    "        #print(\"j:\",j,\"index_Shuffreversed:\",index_Shuffreversed)\n",
    "        offline_NN_pred_shuff.append(shuffled_winners[0,index_Shuffreversed].item())\n",
    "        \n",
    "        #particle[\"offline_NN_pred_shuffled\"] = shuffled_winners[0,index_Shuffreversed].item()\n",
    "        #one_evt.iloc[j] = particle\n",
    "        \n",
    "    #nonHc_FSPs[(nonHc_FSPs[\"__event__\"] == evts[i])] = one_evt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evtnum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-285cc6c1e98e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m NN_results = pd.DataFrame({'__event__': evtnum,\n\u001b[0m\u001b[1;32m      2\u001b[0m                           \u001b[0;34m'label'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           \u001b[0;34m'online_NN_pred'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0monline_NN_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                           \u001b[0;34m'offline_NN_pred'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0moffline_NN_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           'offline_NN_pred_shuff' : offline_NN_pred_shuff})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evtnum' is not defined"
     ]
    }
   ],
   "source": [
    "NN_results = pd.DataFrame({'__event__': evtnum,\n",
    "                          'label' : labels,\n",
    "                          'online_NN_pred' : online_NN_pred,\n",
    "                          'offline_NN_pred' : offline_NN_pred,\n",
    "                          'offline_NN_pred_shuff' : offline_NN_pred_shuff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_results.to_csv(nfs_path + \"NN_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_results = pd.read_csv(nfs_path + \"NN_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_results[\"off_eq_on\"] = (NN_results[\"offline_NN_pred\"] == NN_results[\"online_NN_pred\"]).astype(int)\n",
    "NN_results[\"off_eq_on_shuffled\"] = (NN_results[\"offline_NN_pred_shuff\"] == NN_results[\"online_NN_pred\"]).astype(int)\n",
    "NN_results[\"unshuff_eq_shuff\"] = (NN_results[\"offline_NN_pred_shuff\"] == NN_results[\"offline_NN_pred\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_results[\"correct_pred_onlineNN\"] = (NN_results[\"label\"] == NN_results[\"online_NN_pred\"]).astype(int)\n",
    "NN_results[\"correct_pred_offlineNN\"] = (NN_results[\"label\"] == NN_results[\"offline_NN_pred\"]).astype(int)\n",
    "NN_results[\"correct_pred_offlineNN_shuff\"] = (NN_results[\"label\"] == NN_results[\"offline_NN_pred_shuff\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off_eq_on\n",
      "81.98799066478519 % \n",
      "\n",
      "off_eq_on_shuffled\n",
      "81.9911232872031 % \n",
      "\n",
      "unshuff_eq_shuff\n",
      "81.89016741018985 % \n",
      "\n",
      "correct_pred_onlineNN\n",
      "60.269234657625724 % \n",
      "\n",
      "correct_pred_offlineNN\n",
      "60.0980795600659 % \n",
      "\n",
      "correct_pred_offlineNN_shuff\n",
      "60.12200140398441 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for var in [\"off_eq_on\",\"off_eq_on_shuffled\",\"unshuff_eq_shuff\",\"correct_pred_onlineNN\",\"correct_pred_offlineNN\",\"correct_pred_offlineNN_shuff\"]:\n",
    "    print(var)\n",
    "    print(NN_results[var].mean()*100, '% \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>off_eq_on</th>\n",
       "      <th>correct_pred_onlineNN</th>\n",
       "      <th>correct_pred_offlineNN</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.077611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.294798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   off_eq_on  correct_pred_onlineNN  correct_pred_offlineNN     count\n",
       "0          0                      0                       0  0.026610\n",
       "1          0                      0                       1  0.075899\n",
       "2          0                      1                       0  0.077611\n",
       "3          1                      0                       0  0.294798\n",
       "4          1                      1                       1  0.525082"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_on_pred = pd.DataFrame({'count' : NN_results.groupby( [\"off_eq_on\",\n",
    "                    \"correct_pred_onlineNN\",\"correct_pred_offlineNN\"] ).size() / NN_results.shape[0] }).reset_index()\n",
    "off_on_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare only the events used offline (val set) with the online results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"NAHSA_Gmodes_fixedD0modes/NAHS_allEvts_twoSubs_fixedD0run/NAHSA_no_xyz\"\n",
    "run_folder = \"MC_studies/Dstlnu_Bt_generic/\" #\"run_HcX_globTag/\" \n",
    "run_path = \"/nfs/dust/belle2/user/axelheim/\" + run_folder\n",
    "bsize = 16\n",
    "dataset_dir = Path(run_path + 'data/' + data_folder)\n",
    "\n",
    "\n",
    "sys.path.insert(1, '/afs/desy.de/user/a/axelheim/private/baumbauen/notebooks/')\n",
    "from ah_utils import pad_collate_fn_ah, PhasespaceSet_BranchSeparator\n",
    "\n",
    "collate = pad_collate_fn_ah\n",
    "test_set = PhasespaceSet_BranchSeparator(dataset_dir, 'val')\n",
    "train_set = PhasespaceSet_BranchSeparator(dataset_dir, 'train')\n",
    "import torch\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=bsize, drop_last=True, shuffle=True,  collate_fn=collate)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=bsize, drop_last=True, shuffle=True,  collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: torch.Size([22, 64, 15])\n",
      "winners.shape: torch.Size([64, 22])\n",
      "features.shape: torch.Size([20, 64, 15])\n",
      "winners.shape: torch.Size([64, 20])\n",
      "features.shape: torch.Size([20, 64, 15])\n",
      "winners.shape: torch.Size([64, 20])\n",
      "features.shape: torch.Size([23, 64, 15])\n",
      "winners.shape: torch.Size([64, 23])\n",
      "features.shape: torch.Size([20, 64, 15])\n",
      "winners.shape: torch.Size([64, 20])\n",
      "features.shape: torch.Size([20, 64, 15])\n",
      "winners.shape: torch.Size([64, 20])\n",
      "features.shape: torch.Size([22, 64, 15])\n",
      "winners.shape: torch.Size([64, 22])\n",
      "features.shape: torch.Size([20, 64, 15])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-a0ebae24b2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features.shape:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mSA_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSA_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (N, C, d1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/baum/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/private/baumbauen/notebooks/BranchSeparatorModel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge2node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_rec\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode2edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_send\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l*l, 2d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Skip connection  # (b, l*l, 3d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l*l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/private/baumbauen/notebooks/BranchSeparatorModel.py\u001b[0m in \u001b[0;36mnode2edge\u001b[0;34m(self, x, rel_rec, rel_send)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mreceivers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l*l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0msenders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_send\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l*l, d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msenders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreceivers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, l*l, 2d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(train_set, batch_size=64, drop_last=True, shuffle=True,  collate_fn=collate)\n",
    "\n",
    "dataiter = iter(tmp_loader)\n",
    "for batch_num, batch in enumerate(dataiter):\n",
    "    features, labels, tag = batch\n",
    "    print(\"features.shape:\",features.shape)    \n",
    "    SA_pred = model(features)\n",
    "\n",
    "    probs = torch.softmax(SA_pred, dim=1)  # (N, C, d1)\n",
    "    winners = probs.argmax(dim=1)\n",
    "    print(\"winners.shape:\",winners.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "evts_train=[]\n",
    "for batch_num, batch in enumerate(dataiter):\n",
    "    features, labels, tag = batch\n",
    "    tag = np.array(tag)\n",
    "    for i in range(tag.shape[0]):\n",
    "        tag_tmp = str(tag[i,-1])\n",
    "        event = int(tag_tmp[tag_tmp.find(\"evt\")+3:-1])\n",
    "        evts_train.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 of 3367 batches\n",
      "# 10 of 3367 batches\n",
      "# 20 of 3367 batches\n",
      "# 30 of 3367 batches\n",
      "# 40 of 3367 batches\n",
      "# 50 of 3367 batches\n",
      "# 60 of 3367 batches\n",
      "# 70 of 3367 batches\n",
      "# 80 of 3367 batches\n",
      "# 90 of 3367 batches\n",
      "# 100 of 3367 batches\n",
      "# 110 of 3367 batches\n",
      "# 120 of 3367 batches\n",
      "# 130 of 3367 batches\n",
      "# 140 of 3367 batches\n",
      "# 150 of 3367 batches\n",
      "# 160 of 3367 batches\n",
      "# 170 of 3367 batches\n",
      "# 180 of 3367 batches\n",
      "# 190 of 3367 batches\n",
      "# 200 of 3367 batches\n",
      "# 210 of 3367 batches\n",
      "# 220 of 3367 batches\n",
      "# 230 of 3367 batches\n",
      "# 240 of 3367 batches\n",
      "# 250 of 3367 batches\n",
      "# 260 of 3367 batches\n",
      "# 270 of 3367 batches\n",
      "# 280 of 3367 batches\n",
      "# 290 of 3367 batches\n",
      "# 300 of 3367 batches\n",
      "# 310 of 3367 batches\n",
      "# 320 of 3367 batches\n",
      "# 330 of 3367 batches\n",
      "# 340 of 3367 batches\n",
      "# 350 of 3367 batches\n",
      "# 360 of 3367 batches\n",
      "# 370 of 3367 batches\n",
      "# 380 of 3367 batches\n",
      "# 390 of 3367 batches\n",
      "# 400 of 3367 batches\n",
      "# 410 of 3367 batches\n",
      "# 420 of 3367 batches\n",
      "# 430 of 3367 batches\n",
      "# 440 of 3367 batches\n",
      "# 450 of 3367 batches\n",
      "# 460 of 3367 batches\n",
      "# 470 of 3367 batches\n",
      "# 480 of 3367 batches\n",
      "# 490 of 3367 batches\n",
      "# 500 of 3367 batches\n",
      "# 510 of 3367 batches\n",
      "# 520 of 3367 batches\n",
      "# 530 of 3367 batches\n",
      "# 540 of 3367 batches\n",
      "# 550 of 3367 batches\n",
      "# 560 of 3367 batches\n",
      "# 570 of 3367 batches\n",
      "# 580 of 3367 batches\n",
      "# 590 of 3367 batches\n",
      "# 600 of 3367 batches\n",
      "# 610 of 3367 batches\n",
      "# 620 of 3367 batches\n",
      "# 630 of 3367 batches\n",
      "# 640 of 3367 batches\n",
      "# 650 of 3367 batches\n",
      "# 660 of 3367 batches\n",
      "# 670 of 3367 batches\n",
      "# 680 of 3367 batches\n",
      "# 690 of 3367 batches\n",
      "# 700 of 3367 batches\n",
      "# 710 of 3367 batches\n",
      "# 720 of 3367 batches\n",
      "# 730 of 3367 batches\n",
      "# 740 of 3367 batches\n",
      "# 750 of 3367 batches\n",
      "# 760 of 3367 batches\n",
      "# 770 of 3367 batches\n",
      "# 780 of 3367 batches\n",
      "# 790 of 3367 batches\n",
      "# 800 of 3367 batches\n",
      "# 810 of 3367 batches\n",
      "# 820 of 3367 batches\n",
      "# 830 of 3367 batches\n",
      "# 840 of 3367 batches\n",
      "# 850 of 3367 batches\n",
      "# 860 of 3367 batches\n",
      "# 870 of 3367 batches\n",
      "# 880 of 3367 batches\n",
      "# 890 of 3367 batches\n",
      "# 900 of 3367 batches\n",
      "# 910 of 3367 batches\n",
      "# 920 of 3367 batches\n",
      "# 930 of 3367 batches\n",
      "# 940 of 3367 batches\n",
      "# 950 of 3367 batches\n",
      "# 960 of 3367 batches\n",
      "# 970 of 3367 batches\n",
      "# 980 of 3367 batches\n",
      "# 990 of 3367 batches\n",
      "# 1000 of 3367 batches\n",
      "# 1010 of 3367 batches\n",
      "# 1020 of 3367 batches\n",
      "# 1030 of 3367 batches\n",
      "# 1040 of 3367 batches\n",
      "# 1050 of 3367 batches\n",
      "# 1060 of 3367 batches\n",
      "# 1070 of 3367 batches\n",
      "# 1080 of 3367 batches\n",
      "# 1090 of 3367 batches\n",
      "# 1100 of 3367 batches\n",
      "# 1110 of 3367 batches\n",
      "# 1120 of 3367 batches\n",
      "# 1130 of 3367 batches\n",
      "# 1140 of 3367 batches\n",
      "# 1150 of 3367 batches\n",
      "# 1160 of 3367 batches\n",
      "# 1170 of 3367 batches\n",
      "# 1180 of 3367 batches\n",
      "# 1190 of 3367 batches\n",
      "# 1200 of 3367 batches\n",
      "# 1210 of 3367 batches\n",
      "# 1220 of 3367 batches\n",
      "# 1230 of 3367 batches\n",
      "# 1240 of 3367 batches\n",
      "# 1250 of 3367 batches\n",
      "# 1260 of 3367 batches\n",
      "# 1270 of 3367 batches\n",
      "# 1280 of 3367 batches\n",
      "# 1290 of 3367 batches\n",
      "# 1300 of 3367 batches\n",
      "# 1310 of 3367 batches\n",
      "# 1320 of 3367 batches\n",
      "# 1330 of 3367 batches\n",
      "# 1340 of 3367 batches\n",
      "# 1350 of 3367 batches\n",
      "# 1360 of 3367 batches\n",
      "# 1370 of 3367 batches\n",
      "# 1380 of 3367 batches\n",
      "# 1390 of 3367 batches\n",
      "# 1400 of 3367 batches\n",
      "# 1410 of 3367 batches\n",
      "# 1420 of 3367 batches\n",
      "# 1430 of 3367 batches\n",
      "# 1440 of 3367 batches\n",
      "# 1450 of 3367 batches\n",
      "# 1460 of 3367 batches\n",
      "# 1470 of 3367 batches\n",
      "# 1480 of 3367 batches\n",
      "# 1490 of 3367 batches\n",
      "# 1500 of 3367 batches\n",
      "# 1510 of 3367 batches\n",
      "# 1520 of 3367 batches\n",
      "# 1530 of 3367 batches\n",
      "# 1540 of 3367 batches\n",
      "# 1550 of 3367 batches\n",
      "# 1560 of 3367 batches\n",
      "# 1570 of 3367 batches\n",
      "# 1580 of 3367 batches\n",
      "# 1590 of 3367 batches\n",
      "# 1600 of 3367 batches\n",
      "# 1610 of 3367 batches\n",
      "# 1620 of 3367 batches\n",
      "# 1630 of 3367 batches\n",
      "# 1640 of 3367 batches\n",
      "# 1650 of 3367 batches\n",
      "# 1660 of 3367 batches\n",
      "# 1670 of 3367 batches\n",
      "# 1680 of 3367 batches\n",
      "# 1690 of 3367 batches\n",
      "# 1700 of 3367 batches\n",
      "# 1710 of 3367 batches\n",
      "# 1720 of 3367 batches\n",
      "# 1730 of 3367 batches\n",
      "# 1740 of 3367 batches\n",
      "# 1750 of 3367 batches\n",
      "# 1760 of 3367 batches\n",
      "# 1770 of 3367 batches\n",
      "# 1780 of 3367 batches\n",
      "# 1790 of 3367 batches\n",
      "# 1800 of 3367 batches\n",
      "# 1810 of 3367 batches\n",
      "# 1820 of 3367 batches\n",
      "# 1830 of 3367 batches\n",
      "# 1840 of 3367 batches\n",
      "# 1850 of 3367 batches\n",
      "# 1860 of 3367 batches\n",
      "# 1870 of 3367 batches\n",
      "# 1880 of 3367 batches\n",
      "# 1890 of 3367 batches\n",
      "# 1900 of 3367 batches\n",
      "# 1910 of 3367 batches\n",
      "# 1920 of 3367 batches\n",
      "# 1930 of 3367 batches\n",
      "# 1940 of 3367 batches\n",
      "# 1950 of 3367 batches\n",
      "# 1960 of 3367 batches\n",
      "# 1970 of 3367 batches\n",
      "# 1980 of 3367 batches\n",
      "# 1990 of 3367 batches\n",
      "# 2000 of 3367 batches\n",
      "# 2010 of 3367 batches\n",
      "# 2020 of 3367 batches\n",
      "# 2030 of 3367 batches\n",
      "# 2040 of 3367 batches\n",
      "# 2050 of 3367 batches\n",
      "# 2060 of 3367 batches\n",
      "# 2070 of 3367 batches\n",
      "# 2080 of 3367 batches\n",
      "# 2090 of 3367 batches\n",
      "# 2100 of 3367 batches\n",
      "# 2110 of 3367 batches\n",
      "# 2120 of 3367 batches\n",
      "# 2130 of 3367 batches\n",
      "# 2140 of 3367 batches\n",
      "# 2150 of 3367 batches\n",
      "# 2160 of 3367 batches\n",
      "# 2170 of 3367 batches\n",
      "# 2180 of 3367 batches\n",
      "# 2190 of 3367 batches\n",
      "# 2200 of 3367 batches\n",
      "# 2210 of 3367 batches\n",
      "# 2220 of 3367 batches\n",
      "# 2230 of 3367 batches\n",
      "# 2240 of 3367 batches\n",
      "# 2250 of 3367 batches\n",
      "# 2260 of 3367 batches\n",
      "# 2270 of 3367 batches\n",
      "# 2280 of 3367 batches\n",
      "# 2290 of 3367 batches\n",
      "# 2300 of 3367 batches\n",
      "# 2310 of 3367 batches\n",
      "# 2320 of 3367 batches\n",
      "# 2330 of 3367 batches\n",
      "# 2340 of 3367 batches\n",
      "# 2350 of 3367 batches\n",
      "# 2360 of 3367 batches\n",
      "# 2370 of 3367 batches\n",
      "# 2380 of 3367 batches\n",
      "# 2390 of 3367 batches\n",
      "# 2400 of 3367 batches\n",
      "# 2410 of 3367 batches\n",
      "# 2420 of 3367 batches\n",
      "# 2430 of 3367 batches\n",
      "# 2440 of 3367 batches\n",
      "# 2450 of 3367 batches\n",
      "# 2460 of 3367 batches\n",
      "# 2470 of 3367 batches\n",
      "# 2480 of 3367 batches\n",
      "# 2490 of 3367 batches\n",
      "# 2500 of 3367 batches\n",
      "# 2510 of 3367 batches\n",
      "# 2520 of 3367 batches\n",
      "# 2530 of 3367 batches\n",
      "# 2540 of 3367 batches\n",
      "# 2550 of 3367 batches\n",
      "# 2560 of 3367 batches\n",
      "# 2570 of 3367 batches\n",
      "# 2580 of 3367 batches\n",
      "# 2590 of 3367 batches\n",
      "# 2600 of 3367 batches\n",
      "# 2610 of 3367 batches\n",
      "# 2620 of 3367 batches\n",
      "# 2630 of 3367 batches\n",
      "# 2640 of 3367 batches\n",
      "# 2650 of 3367 batches\n",
      "# 2660 of 3367 batches\n",
      "# 2670 of 3367 batches\n",
      "# 2680 of 3367 batches\n",
      "# 2690 of 3367 batches\n",
      "# 2700 of 3367 batches\n",
      "# 2710 of 3367 batches\n",
      "# 2720 of 3367 batches\n",
      "# 2730 of 3367 batches\n",
      "# 2740 of 3367 batches\n",
      "# 2750 of 3367 batches\n",
      "# 2760 of 3367 batches\n",
      "# 2770 of 3367 batches\n",
      "# 2780 of 3367 batches\n",
      "# 2790 of 3367 batches\n",
      "# 2800 of 3367 batches\n",
      "# 2810 of 3367 batches\n",
      "# 2820 of 3367 batches\n",
      "# 2830 of 3367 batches\n",
      "# 2840 of 3367 batches\n",
      "# 2850 of 3367 batches\n",
      "# 2860 of 3367 batches\n",
      "# 2870 of 3367 batches\n",
      "# 2880 of 3367 batches\n",
      "# 2890 of 3367 batches\n",
      "# 2900 of 3367 batches\n",
      "# 2910 of 3367 batches\n",
      "# 2920 of 3367 batches\n",
      "# 2930 of 3367 batches\n",
      "# 2940 of 3367 batches\n",
      "# 2950 of 3367 batches\n",
      "# 2960 of 3367 batches\n",
      "# 2970 of 3367 batches\n",
      "# 2980 of 3367 batches\n",
      "# 2990 of 3367 batches\n",
      "# 3000 of 3367 batches\n",
      "# 3010 of 3367 batches\n",
      "# 3020 of 3367 batches\n",
      "# 3030 of 3367 batches\n",
      "# 3040 of 3367 batches\n",
      "# 3050 of 3367 batches\n",
      "# 3060 of 3367 batches\n",
      "# 3070 of 3367 batches\n",
      "# 3080 of 3367 batches\n",
      "# 3090 of 3367 batches\n",
      "# 3100 of 3367 batches\n",
      "# 3110 of 3367 batches\n",
      "# 3120 of 3367 batches\n",
      "# 3130 of 3367 batches\n",
      "# 3140 of 3367 batches\n",
      "# 3150 of 3367 batches\n",
      "# 3160 of 3367 batches\n",
      "# 3170 of 3367 batches\n",
      "# 3180 of 3367 batches\n",
      "# 3190 of 3367 batches\n",
      "# 3200 of 3367 batches\n",
      "# 3210 of 3367 batches\n",
      "# 3220 of 3367 batches\n",
      "# 3230 of 3367 batches\n",
      "# 3240 of 3367 batches\n",
      "# 3250 of 3367 batches\n",
      "# 3260 of 3367 batches\n",
      "# 3270 of 3367 batches\n",
      "# 3280 of 3367 batches\n",
      "# 3290 of 3367 batches\n",
      "# 3300 of 3367 batches\n",
      "# 3310 of 3367 batches\n",
      "# 3320 of 3367 batches\n",
      "# 3330 of 3367 batches\n",
      "# 3340 of 3367 batches\n",
      "# 3350 of 3367 batches\n",
      "# 3360 of 3367 batches\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "evts=[]\n",
    "preds=[]\n",
    "labs=[]\n",
    "corrects=[]\n",
    "\n",
    "for batch_num, batch in enumerate(dataiter):\n",
    "    if batch_num % 10 == 0:\n",
    "        print(\"#\",(batch_num),\"of\",len(test_loader),\"batches\")\n",
    "    features, labels, tag = batch\n",
    "    tag = np.array(tag)\n",
    "    \n",
    "    SA_pred = model(features)\n",
    "\n",
    "    probs = torch.softmax(SA_pred, dim=1)  # (N, C, d1)\n",
    "    winners = probs.argmax(dim=1)\n",
    "    #print(\"winners.shape:\",winners.shape)\n",
    "    #print(\"labels.shape:\",labels.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(winners.shape[0]):\n",
    "        tag_tmp = str(tag[i,-1])\n",
    "        event = int(tag_tmp[tag_tmp.find(\"evt\")+3:-1])\n",
    "        #print(\"winners[i,:]:\",winners[i,:])\n",
    "        #print(\"labels[i,:]:\",labels[i,:])\n",
    "        for j in range(winners.shape[1]):\n",
    "            evts.append(event)\n",
    "\n",
    "            pred = winners[i,j].item()\n",
    "            preds.append(pred)\n",
    "            \n",
    "            label = labels[i,j].item()\n",
    "            labs.append(label)\n",
    "            \n",
    "            #print(\"label:\",label,\"winners:\",pred)\n",
    "            \n",
    "            correct = int(label == pred)\n",
    "            corrects.append(correct)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_padded = pd.DataFrame({\"event\":evts, \"label\":labs,\"prediction\":preds,\"correct\":corrects})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of padded entries\n",
    "offline_preds_padded = offline_preds_padded[offline_preds_padded[\"label\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695868"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_preds_padded.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   695858.000\n",
       "mean         0.750\n",
       "std          0.433\n",
       "min          0.000\n",
       "25%          1.000\n",
       "50%          1.000\n",
       "75%          1.000\n",
       "max          1.000\n",
       "Name: corr, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "offline_preds_padded[\"corr\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_and_offline = NN_results[NN_results['__event__'].isin(evts)]\n",
    "on_and_offline_train = NN_results[NN_results['__event__'].isin(evts_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2033\n",
      "8444\n"
     ]
    }
   ],
   "source": [
    "print(on_and_offline['__event__'].nunique())\n",
    "print(on_and_offline_train['__event__'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off_eq_on\n",
      "81.98799066478519 %\n",
      "82.99468684591854 %\n",
      "83.53381218242268 % \n",
      "\n",
      "off_eq_on_shuffled\n",
      "81.9911232872031 %\n",
      "83.09450974078248 %\n",
      "83.45853459632394 % \n",
      "\n",
      "unshuff_eq_shuff\n",
      "81.89016741018985 %\n",
      "83.40685879890518 %\n",
      "83.2703406310771 % \n",
      "\n",
      "correct_pred_onlineNN\n",
      "60.269234657625724 %\n",
      "66.75253582353888 %\n",
      "67.04880496832068 % \n",
      "\n",
      "correct_pred_offlineNN\n",
      "60.0980795600659 %\n",
      "67.04878441474803 %\n",
      "66.99861991092152 % \n",
      "\n",
      "correct_pred_offlineNN_shuff\n",
      "60.12200140398441 %\n",
      "66.86201899855095 %\n",
      "67.0833071952826 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for var in [\"off_eq_on\",\"off_eq_on_shuffled\",\"unshuff_eq_shuff\",\"correct_pred_onlineNN\",\"correct_pred_offlineNN\",\"correct_pred_offlineNN_shuff\"]:\n",
    "    print(var)\n",
    "    print(NN_results[var].mean()*100, '%')    \n",
    "    print(on_and_offline[var].mean()*100, '%')    \n",
    "    print(on_and_offline_train[var].mean()*100, '% \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do it again with offline, but unpadded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize = 1\n",
    "test_loader_unpadded = torch.utils.data.DataLoader(test_set, batch_size=bsize, drop_last=True, shuffle=True,  collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 of 53877 batches\n",
      "# 1000 of 53877 batches\n",
      "# 2000 of 53877 batches\n",
      "# 3000 of 53877 batches\n",
      "# 4000 of 53877 batches\n",
      "# 5000 of 53877 batches\n",
      "# 6000 of 53877 batches\n",
      "# 7000 of 53877 batches\n",
      "# 8000 of 53877 batches\n",
      "# 9000 of 53877 batches\n",
      "# 10000 of 53877 batches\n",
      "# 11000 of 53877 batches\n",
      "# 12000 of 53877 batches\n",
      "# 13000 of 53877 batches\n",
      "# 14000 of 53877 batches\n",
      "# 15000 of 53877 batches\n",
      "# 16000 of 53877 batches\n",
      "# 17000 of 53877 batches\n",
      "# 18000 of 53877 batches\n",
      "# 19000 of 53877 batches\n",
      "# 20000 of 53877 batches\n",
      "# 21000 of 53877 batches\n",
      "# 22000 of 53877 batches\n",
      "# 23000 of 53877 batches\n",
      "# 24000 of 53877 batches\n",
      "# 25000 of 53877 batches\n",
      "# 26000 of 53877 batches\n",
      "# 27000 of 53877 batches\n",
      "# 28000 of 53877 batches\n",
      "# 29000 of 53877 batches\n",
      "# 30000 of 53877 batches\n",
      "# 31000 of 53877 batches\n",
      "# 32000 of 53877 batches\n",
      "# 33000 of 53877 batches\n",
      "# 34000 of 53877 batches\n",
      "# 35000 of 53877 batches\n",
      "# 36000 of 53877 batches\n",
      "# 37000 of 53877 batches\n",
      "# 38000 of 53877 batches\n",
      "# 39000 of 53877 batches\n",
      "# 40000 of 53877 batches\n",
      "# 41000 of 53877 batches\n",
      "# 42000 of 53877 batches\n",
      "# 43000 of 53877 batches\n",
      "# 44000 of 53877 batches\n",
      "# 45000 of 53877 batches\n",
      "# 46000 of 53877 batches\n",
      "# 47000 of 53877 batches\n",
      "# 48000 of 53877 batches\n",
      "# 49000 of 53877 batches\n",
      "# 50000 of 53877 batches\n",
      "# 51000 of 53877 batches\n",
      "# 52000 of 53877 batches\n",
      "# 53000 of 53877 batches\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader_unpadded)\n",
    "evts=[]\n",
    "preds=[]\n",
    "labs=[]\n",
    "corrects=[]\n",
    "\n",
    "for batch_num, batch in enumerate(dataiter):\n",
    "    if batch_num % 1000 == 0:\n",
    "        print(\"#\",(batch_num),\"of\",len(test_loader_unpadded),\"batches\")\n",
    "    features, labels, tag = batch\n",
    "    tag = np.array(tag)\n",
    "    \n",
    "    SA_pred = model(features)\n",
    "\n",
    "    probs = torch.softmax(SA_pred, dim=1)  # (N, C, d1)\n",
    "    winners = probs.argmax(dim=1)\n",
    "    #print(\"winners.shape:\",winners.shape)\n",
    "    #print(\"labels.shape:\",labels.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(winners.shape[0]):\n",
    "        tag_tmp = str(tag[i,-1])\n",
    "        event = int(tag_tmp[tag_tmp.find(\"evt\")+3:-1])\n",
    "        #print(\"winners[i,:]:\",winners[i,:])\n",
    "        #print(\"labels[i,:]:\",labels[i,:])\n",
    "        for j in range(winners.shape[1]):\n",
    "            evts.append(event)\n",
    "\n",
    "            pred = winners[i,j].item()\n",
    "            preds.append(pred)\n",
    "            \n",
    "            label = labels[i,j].item()\n",
    "            labs.append(label)\n",
    "            \n",
    "            #print(\"label:\",label,\"winners:\",pred)\n",
    "            \n",
    "            correct = int(label == pred)\n",
    "            corrects.append(correct)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_unpadded = pd.DataFrame({\"event\":evts, \"label\":labs,\"prediction\":preds,\"correct\":corrects})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6355035707614272"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_preds_unpadded[\"correct\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695868"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_preds_padded.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7505575770117321"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_preds_padded[\"correct\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695868"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_preds_padded.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save offline padded/unpadded results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_preds_unpadded.to_csv(nfs_path + \"offline_preds_unpadded.csv\")\n",
    "offline_preds_padded.to_csv(nfs_path + \"offline_preds_padded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Size([numParticles, 1, numVars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6748, 0.4451, 0.3961, 0.5804]],\n",
      "\n",
      "        [[0.0027, 0.1085, 0.7915, 0.5823]],\n",
      "\n",
      "        [[0.4262, 0.2239, 0.2660, 0.3856]],\n",
      "\n",
      "        [[0.5164, 0.4531, 0.5464, 0.5993]],\n",
      "\n",
      "        [[0.6673, 0.0881, 0.6711, 0.6094]],\n",
      "\n",
      "        [[0.2769, 0.4824, 0.9434, 0.6696]]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0730, 0.0636, 0.4005, 0.7672]],\n",
      "\n",
      "        [[0.7806, 0.7088, 0.5083, 0.7090]],\n",
      "\n",
      "        [[0.5421, 0.5441, 0.0406, 0.8689]],\n",
      "\n",
      "        [[0.0382, 0.3284, 0.9462, 0.7230]],\n",
      "\n",
      "        [[0.4337, 0.9257, 0.2905, 0.4833]],\n",
      "\n",
      "        [[0.9107, 0.2545, 0.5194, 0.6152]]])\n",
      "[1 1 1 0 0 1 1 0 0 0 1]\n",
      "tensor([[[ 0.0730,  0.0636,  0.4005,  0.7672]],\n",
      "\n",
      "        [[ 0.7806,  0.7088,  0.5083,  0.7090]],\n",
      "\n",
      "        [[ 0.5421,  0.5441,  0.0406,  0.8689]],\n",
      "\n",
      "        [[-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "        [[-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "        [[ 0.0382,  0.3284,  0.9462,  0.7230]],\n",
      "\n",
      "        [[ 0.4337,  0.9257,  0.2905,  0.4833]],\n",
      "\n",
      "        [[-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "        [[-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "        [[-1.0000, -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "        [[ 0.9107,  0.2545,  0.5194,  0.6152]]])\n"
     ]
    }
   ],
   "source": [
    "numParticles = 6\n",
    "x = torch.rand(numParticles, 1, 4)\n",
    "\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "print(x) # prints the whole tensor\n",
    "\n",
    "\n",
    "pad_dim = 11\n",
    "\n",
    "N = pad_dim \n",
    "K = pad_dim - numParticles # K zeros, N-K ones\n",
    "padd_array = np.array([0] * K + [1] * (N-K))\n",
    "np.random.shuffle(padd_array)\n",
    "print(padd_array)\n",
    "\n",
    "x_padded = torch.ones(pad_dim, 1, 4) * -1.\n",
    "\n",
    "particle_counter = 0\n",
    "for i in range(pad_dim):\n",
    "    do_pad = padd_array[i]\n",
    "    if do_pad == 1:    \n",
    "        #print(i)\n",
    "        #print(x[particle_counter,:,:])\n",
    "        \n",
    "        x_padded[i,:,:] = x[particle_counter,:,:]\n",
    "\n",
    "        particle_counter += 1\n",
    "        \n",
    "print(x_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1, pad_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = torch.tensor([[ 0.],\n",
    "        [ 1.],\n",
    "        [ 2.],\n",
    "        [-1.],\n",
    "        [-1.],\n",
    "        [ 3.],\n",
    "        [ 4.],\n",
    "        [-1.],\n",
    "        [-1.],\n",
    "        [-1.],\n",
    "        [ 5.]])\n",
    "winners = winners.reshape(1, pad_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winners.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2., -1., -1.,  3.,  4., -1., -1., -1.,  5.]])\n"
     ]
    }
   ],
   "source": [
    "print(winners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3., 4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "num_particles = numParticles\n",
    "\n",
    "\n",
    "winners_unpadded = torch.empty(1, num_particles)\n",
    "particle_counter = 0\n",
    "for i in range(pad_dim):\n",
    "    do_pad = padd_array[i]\n",
    "    if do_pad == 1:  \n",
    "        winners_unpadded[0, particle_counter] = winners[0, i]\n",
    "        particle_counter += 1\n",
    "        \n",
    "print(winners_unpadded)\n",
    "\n",
    "winners=winners_unpadded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
